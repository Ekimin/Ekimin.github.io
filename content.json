[{"title":"译文 Footprints on the Blockchain:Information Leakage in Distributed Ledgers","date":"2017-03-16T12:53:35.000Z","path":"2017/03/16/trans-footprints-on-blockchain/","text":"摘要 This paper examines information leakage in distributed ledgers. We show how the lack of time priority in the period between the publication of a transaction and its validation by miners or designated participants can expose a transaction’s “footprint” to the market, resulting in potential front-running and manipulation. 这篇文章研究了分布式账本技术中的信息泄露问题。我们演示了在交易的公布到比特币矿机或者特定参与者证实交易有效这段时间中，缺乏时序是怎样揭示出交易走向市场的“脚印”，从而导致潜在的非法预先交易和操作。 We propose a cryptology-based approach for solving information leakage problems in distributed ledgers that relies on using a “hash” (or mathematical identifier) to secure time-priority followed by a second communication revealing more features of the underlying market transaction. Solving the information leakage problem greatly expands the potential applications of private distributed ledger technology. 为了解决分布式账本技术中信息泄露问题，我们提出了一个基于密码学的方法。该方法通过“哈希”（或者其他数学标识符）和紧随其后的可以显示更多潜在市场交易信息的二次通讯信息来确保交易时序。信息泄露问题的解决可以增加个人分布式账本技术的潜在应用。 Introduction Advocates of the blockchain, the distributed ledger technology that underlies Bitcoin,see an almost limitless future for the innovation. Apart from its role in cryptocurrencies,distributed ledger technologies are being developed to handle stock trades, clear and settle leveraged loans, handle catastrophe reinsurance, keep track of land titles and transactions,track the ownership of intellectual properties, facilitate peer-to-peer marketplaces – the list goes on and on. Much of the appeal of the blockchain lies in its use of a decentralized distributed ledger technology in which an immutable single record emerges of the various transactions encased in the blocks. The ability to trade assets in such a setting, along with the emergence of new “smart contracts” that can automatically trigger additional steps such as recording ownership changes or authorizing payments, can have, in the words of the Bank of England, “far-reaching implications for the financial industry”. 用于比特币中的分布式账本技术——区块链技术的先驱者，见证了它在技术革命中的广泛应用前景。除了在加密货币中的应用，分布式账本技术还广泛应用于股票交易， 解决杠杆贷款问题，处理巨灾再保险，跟踪解决土地所有权相关事务，知识产权的所有权鉴定，促进P2P市场发展等等。区块链的吸引力很大程度上来自于其使用分散的分布式账本技术，该技术通过不可变单记录反映区块中各种可变的事务。分布式账本技术处理资产交易的能力，连同可以自动触发额外步骤如记录交易变化的所有者或者授权支付的“智慧合同”的出现，将对金融业产生深远的影响。","tags":[{"name":"Academic","slug":"Academic","permalink":"https://wentuotuo.com/tags/Academic/"},{"name":"区块链","slug":"区块链","permalink":"https://wentuotuo.com/tags/区块链/"},{"name":"信息泄露","slug":"信息泄露","permalink":"https://wentuotuo.com/tags/信息泄露/"}]},{"title":"文件编码批量转换为UTF-8","date":"2017-03-15T12:13:24.000Z","path":"2017/03/15/Python/encoding-trans-python/","text":"用 Python 实现的批量转换文件编码为UTF-8 1234567891011121314151617181920212223242526272829303132333435363738# -*- coding:utf-8 -*-import os,sysimport chardetdef convert( filename, in_enc = \"GBK\", out_enc=\"UTF8\" ): try: print (\"convert \" + filename,) content = open(filename,'rb').read() result = chardet.detect(content)#通过chardet.detect获取当前文件的编码格式串，返回类型为字典类型 coding = result.get('encoding')#获取encoding的值[编码格式] if coding != 'utf-8':#文件格式如果不是utf-8的时候，才进行转码 print (\"to utf-8!\") new_content = content.decode(in_enc).encode(out_enc) open(filename, 'wb').write(new_content) print (\" done\") else: print (coding) except IOError as e: # except: print (\" error\")def explore(dir): for root, dirs, files in os.walk(dir): for file in files: path = os.path.join(root, file) convert(path)def main(): for path in sys.argv[1:]: if os.path.isfile(path): convert(path) elif os.path.isdir(path): explore(path)if __name__ == \"__main__\": main() 执行该文件需要 chardet，安装chardet： 安装pip （3.4版本及以后版本都已经默认安装了pip）https://pip.pypa.io/en/stable/installing/ Windows下需要添加pip环境变量 下载 chardet https://pypi.python.org/pypi/chardet 下载chardet-2.3.0.tar.gz (md5) 解压，进入解压后的目录 python setup.py install 安装","tags":[{"name":"编码","slug":"编码","permalink":"https://wentuotuo.com/tags/编码/"},{"name":"乱码","slug":"乱码","permalink":"https://wentuotuo.com/tags/乱码/"},{"name":"UTF-8","slug":"UTF-8","permalink":"https://wentuotuo.com/tags/UTF-8/"},{"name":"Python","slug":"Python","permalink":"https://wentuotuo.com/tags/Python/"},{"name":"GBK","slug":"GBK","permalink":"https://wentuotuo.com/tags/GBK/"}]},{"title":"Atom 手册","date":"2017-03-14T16:00:00.000Z","path":"2017/03/15/工具/atom-manual/","text":"Atom 手册 输入apm查看是否安装了Atom Package Manager. 123456789101112131415161718192021C:\\Users\\ymhe&gt;apmapm - Atom Package Manager powered by https://atom.ioUsage: apm &lt;command&gt;where &lt;command&gt; is one of: clean, config, dedupe, deinstall, delete, dev, develop, disable, docs, enable, erase, featured, home, i, init, install, link, linked, links, list, ln, lns, login, ls, open, outdated, publish, rebuild, rebuild-module-cache, remove, rm, search, show, star, starred, stars, test, uninstall, unlink, unpublish, unstar, update, upgrade, view.Run `apm help &lt;command&gt;` to see the more details about a specific command.Options: --color Enable colored output [boolean] [default: true] -v, --version Print the apm version -h, --help Print this usage message Prefix an option with `no-` to set it to false such as --no-color to disable colored output. 安装汉化插件 12C:\\Users\\ymhe&gt;apm install simplified-chinese-menuInstalling simplified-chinese-menu to C:\\Users\\ymhe\\.atom\\packages done 安装 minimap 12C:\\Users\\ymhe&gt;apm install minimapInstalling minimap to C:\\Users\\ymhe\\.atom\\packages done 开启 markdown 预览 菜单栏 扩展-Markdown Preview-Toggle Preview 有没有感觉很酷炫 terminal-plus cmd+` 打开终端 插件设置中可以改变shell","tags":[{"name":"Atom","slug":"Atom","permalink":"https://wentuotuo.com/tags/Atom/"},{"name":"工具","slug":"工具","permalink":"https://wentuotuo.com/tags/工具/"}]},{"title":"Git 教程","date":"2017-03-01T12:13:39.000Z","path":"2017/03/01/工具/git-tutorial/","text":"目录： Git 教程 使用 github 作为 git 托管服务器 Git 常用命令汇总 Git 教程安装Git 首先确认服务器是否安装Git 12[root@iZj6c2vq0s1w6wkap2geanZ ~]# rpm -qa gitgit-1.7.1-3.el6_4.1.x86_64 若没有，则安装1$ yum install git 建一个git用户，用来运行git服务 添加用户 1[root@iZj6c2vq0s1w6wkap2geanZ ~]# adduser git 此时在阿里云服务器的根目录：/home文件夹下会自动新增一个文件夹git 按这个层级建立文件用于存放客户端用户的公钥：/home/git/.ssh/authorized_keys 在本地客户端的git bash中通过命令：（windows先装Git客户端） 12345678910111213141516171819202122$ ssh-keygen -t rsa -C &quot;heyiminwork@gmail.com&quot;Generating public/private rsa key pair.Enter file in which to save the key (/c/Users/ymhe/.ssh/id_rsa):Created directory &apos;/c/Users/ymhe/.ssh&apos;.Enter passphrase (empty for no passphrase):Enter same passphrase again:Your identification has been saved in /c/Users/ymhe/.ssh/id_rsa.Your public key has been saved in /c/Users/ymhe/.ssh/id_rsa.pub.The key fingerprint is:SHA256:Wfx6+z6eD/Qn73vMmDugoe20otVTQjWEAxlT7+TcrWk heyiminwork@gmail.comThe key&apos;s randomart image is:+---[RSA 2048]----+| +=.o+ || .ooo . || +.o || + * . . || S . * o .|| ..+.. + || .o=o..E=o|| .o.o+ o===|| .. oo .+*B*|+----[SHA256]-----+ 命令生成公钥，默认在c盘：用户/.ssh中id_rsa.pub文件是公钥，用记事本打开复制粘贴到服务器的/home/git/.ssh/authorized_keys文件中即可。 服务器中建立git仓库 自己在服务器根目录新建一个专门用于存放仓库的git文件夹，如/usr/git通过如下代码创建并初始化仓库,此时是以个空仓库：1[root@iZj6c2vq0s1w6wkap2geanZ git]# git init --bare sample.git 裸仓库没有working dir，因为服务器上的git仓库纯粹是为了共享，仓库目录一般以.git结尾。然后把owner改为git： 1234[root@iZj6c2vq0s1w6wkap2geanZ git]# chown -R git:git sample.git[root@iZj6c2vq0s1w6wkap2geanZ git]# lltotal 4drwxr-xr-x 7 git git 4096 Nov 18 10:37 sample.git 禁止git用户登录Shell出于安全考虑，git用户不应该登录shell。修改方法：编辑/etc/passwd，找到类似一行：git:x:500:500::/home/git:/bin/bash改为git:x:500:500::/home/git:/usr/bin/git-shell这样，git用户可以正常通过ssh使用git，但无法登录shell。 克隆仓库在Git Bash客户端就可以通过ssh克隆仓库了： 12345678910111213ymhe@DESKTOP-B29K8H5 MINGW64 /e/git$ git clone git@47.90.56.252:/usr/git/sample.gitCloning into &apos;sample&apos;...The authenticity of host &apos;47.90.56.252 (47.90.56.252)&apos; can&apos;t be established.RSA key fingerprint is SHA256:uc0hmvJyknGJsyCyFWrcO/BXAK4CEqo8bVobSSccmNg.Are you sure you want to continue connecting (yes/no)? yesWarning: Permanently added &apos;47.90.56.252&apos; (RSA) to the list of known hosts.warning: You appear to have cloned an empty repository.ymhe@DESKTOP-B29K8H5 MINGW64 /e/git$ lltotal 0drwxr-xr-x 1 ymhe 197121 0 11月 18 10:46 sample/ 使用 Github准备工作 注册账号全球最大同性交友社区 安装&amp;配置git 安装git Linux一般linux系统自带git，没有的话可以到对应仓库安装 123yum install git# orapt-get install git Windows &amp; Mac直接下载github Desktop客户端安装 配置git 生成本地 ssh key1ssh-keygen -t rsa -C &quot;emailsample@gmail.com&quot; #Email为github上注册的邮箱 之后会要求确认路径和输入密码，使用默认的一路回车就行。成功的话会在~/下生成.ssh文件夹，进去，打开id_rsa.pub，复制里面的key。（id_rsa是私钥，id_rsa.pub是公钥） 添加公钥添加到github登录github上，进入 Account Settings，左边选择SSH and GPG Keys，New SSH Key,title随便填，粘贴在你电脑上生成的公钥。 验证ssh key是否生效 12#本地shell执行ssh -T git@github.com 第一次的会提示是否continue，输入yes就会看到：You’ve successfully authenticated, but GitHub does not provide shell access 。这就表示已成功连上github。 设置username email12git config --global user.name &quot;Ekimin&quot; #双引号中为用户名git config --global user.email &quot;heyiminwork@gmail.com&quot; 这个命令，会在“~/.gitconfig”中以如下形式输出设置文件：1234[ymhe@iZ114e8q2mjZ ~]$ cat ~/.gitconfig[user] name = Ekimin email = heyiminwork@gmail.com 想更改这些信息时，可以直接编辑这个设置文件。这里设置的姓名和邮箱地址会用在Git的提交日志中。由于在GitHub上公开仓库时，这里的姓名和邮箱地址也会随着提交日志一同被公开，所以请不要使用不便公开的隐私信息。 提高命令的可读性 1[ymhe@iZ114e8q2mjZ ~]$ git config --global color.ui auto 使用github创建仓库在主页点击创建仓库 New repository新建仓库时： Initialize this repository with a README 支持MarkDown语法，一般新仓库都建议勾选该项 Add .gitignore 这个设定会帮我们把不需要在Git仓库中进行版本管理的文件记录在.gitignore文件中，省去了每次根据框架进行设置的麻烦。 Add a license 许可协议文件。如果这个仓库中包含的代码已经确定了许可协议，那么请在这里进行选择。随后将自动生成包含许可协议内容的LICENSE 文件，用来表明该仓库内容的许可协议。 仓库创建好后，链接为：https://github.com/用户名/Hello-Word拓展：公开时的许可协议: 公开代码 克隆新建的仓库github主页或者客户端中都可以获取仓库SSH代码，用于检出。 1234567891011[ymhe@iZ114e8q2mjZ git]$ git clone git@github.com:Ekimin/hello-world.gitInitialized empty Git repository in /home/ymhe/git/hello-world/.git/remote: Counting objects: 13, done.remote: Compressing objects: 100% (8/8), done.remote: Total 13 (delta 1), reused 3 (delta 0), pack-reused 0Receiving objects: 100% (13/13), done.Resolving deltas: 100% (1/1), done.#clone的仓库会保存在当前目录下[ymhe@iZ114e8q2mjZ git]$ lltotal 4drwxr-xr-x 3 ymhe ymhe 4096 Sep 30 14:52 hello-world 进入目录，新建测试文件hello-world.php 12345[ymhe@iZ114e8q2mjZ git]$ cd hello-world/[ymhe@iZ114e8q2mjZ hello-world]$ lltotal 4-rw-rw-r-- 1 ymhe ymhe 145 Sep 30 14:52 README.md[ymhe@iZ114e8q2mjZ hello-world]$ vim hello-world.php #随便写点东西进去 查看状态 1234567[ymhe@iZ114e8q2mjZ hello-world]$ git status# On branch master# Untracked files:# (use &quot;git add &lt;file&gt;...&quot; to include in what will be committed)## hello-world.phpnothing added to commit but untracked files present (use &quot;git add&quot; to track) 由于新建的文件还没有提交到git仓库，所以显示为“Untracked files”。 提交 将hello-world.php提交至仓库,这样一来，这个文件就进入了版本管理系统的管理之下。今后的更改管理都交由Git进行。 12345[ymhe@iZ114e8q2mjZ hello-world]$ git add hello-world.php[ymhe@iZ114e8q2mjZ hello-world]$ git commit -m &quot;Add hello-world.php&quot;[master 9cd88ce] Add hello-world.php 1 files changed, 3 insertions(+), 0 deletions(-) create mode 100644 hello-world.php git add 命令将文件提交至暂存区(在Index数据结构中记录文件提交之前的状态。)，再通过git commit提交，-m参数后添加本次提交的备注 查看日志 123456[ymhe@iZ114e8q2mjZ hello-world]$ git logcommit 9cd88ce54ba90d64d5908b20dd4571ae6fdfda60Author: Ekimin &lt;heyiminwork@gmail.com&gt;Date: Fri Sep 30 15:17:42 2016 +0800 Add hello-world.php 进行push push会更新github上的仓库。 12345678[ymhe@iZ114e8q2mjZ hello-world]$ git pushWarning: Permanently added the RSA host key for IP address &apos;192.30.253.113&apos; to the list of known hosts.Counting objects: 4, done.Compressing objects: 100% (2/2), done.Writing objects: 100% (3/3), 316 bytes, done.Total 3 (delta 0), reused 0 (delta 0)To git@github.com:Ekimin/hello-world.git 0223614..9cd88ce master -&gt; master 至此，修改的代码便在github上公开了。可以查看链接http://github.com/用户名/hello-world Git 常用命令汇总初始化 git init1git init [-q | --quiet] [--bare] [--template=&lt;template-directory&gt;] [--shared[=&lt;permissions&gt;]] [&lt;directory&gt;] 在当前目录初始化一个仓库 12E:\\IDEA\\AlgoliaSearch&gt;git initInitialized empty Git repository in E:/IDEA/AlgoliaSearch/.git/ 在当前目录初始化一个裸库 1git init --bare 添加远程仓库1git remote add [&lt;options&gt;] &lt;name&gt; &lt;url&gt; 1E:\\IDEA\\AlgoliaSearch&gt;git remote add origin git@github.com:Ekimin/AlgoliaSearch.git 第一次 push 到远程仓库123456789E:\\IDEA\\AlgoliaSearch&gt;git push --set-upstream origin masterCounting objects: 4, done.Delta compression using up to 2 threads.Compressing objects: 100% (4/4), done.Writing objects: 100% (4/4), 1.14 KiB | 0 bytes/s, done.Total 4 (delta 0), reused 0 (delta 0)To github.com:Ekimin/AlgoliaSearch.git * [new branch] master -&gt; masterBranch master set up to track remote branch master from origin. 场景：在本地新建分支 dev，push到远程仓库（远程没有dev分支）1234567891011121314151617E:\\IDEA\\AlgoliaSearch&gt;git branch* masterE:\\IDEA\\AlgoliaSearch&gt;git branch devE:\\IDEA\\AlgoliaSearch&gt;git branch dev* masterE:\\IDEA\\AlgoliaSearch&gt;git checkout devSwitched to branch &apos;dev&apos;E:\\IDEA\\AlgoliaSearch&gt;git push --set-upstream origin devTotal 0 (delta 0), reused 0 (delta 0)To github.com:Ekimin/AlgoliaSearch.git * [new branch] dev -&gt; devBranch dev set up to track remote branch dev from origin. 删除分支 dev 删除本地分支 dev12git branch -d &lt;branch-name&gt;git branch -D &lt;branch-name&gt; #强制删除（分支没有merge也会被删除） 12345678910111213141516E:\\IDEA\\AlgoliaSearch&gt;git branch* dev masterE:\\IDEA\\AlgoliaSearch&gt;git branch -d deverror: Cannot delete branch &apos;dev&apos; checked out at &apos;E:/IDEA/AlgoliaSearch&apos;E:\\IDEA\\AlgoliaSearch&gt;git checkout masterSwitched to branch &apos;master&apos;Your branch is up-to-date with &apos;origin/master&apos;.E:\\IDEA\\AlgoliaSearch&gt;git branch -d devDeleted branch dev (was 74a7280).E:\\IDEA\\AlgoliaSearch&gt;git branch* master 删除远程分支 dev 123E:\\IDEA\\AlgoliaSearch&gt;git push origin :devTo github.com:Ekimin/AlgoliaSearch.git - [deleted] dev add添加到缓存区、commit提交、push推送123git add [&lt;options&gt;] [--] &lt;pathspec&gt;...git commit [&lt;options&gt;] [--] &lt;pathspec&gt;...git push [&lt;options&gt;] [&lt;repository&gt; [&lt;refspec&gt;...]] 12345678910111213141516171819202122232425E:\\IDEA\\AlgoliaSearch&gt;git statusOn branch masterYour branch is up-to-date with &apos;origin/master&apos;.Untracked files: (use &quot;git add &lt;file&gt;...&quot; to include in what will be committed) src/nothing added to commit but untracked files present (use &quot;git add&quot; to track)E:\\IDEA\\AlgoliaSearch&gt;git add .E:\\IDEA\\AlgoliaSearch&gt;git commit -m &quot;new class&quot;[master 978b221] new class 1 file changed, 8 insertions(+) create mode 100644 src/main/java/com/wentuouto/algolia/app/Algolia.javaE:\\IDEA\\AlgoliaSearch&gt;git push origin masterCounting objects: 10, done.Delta compression using up to 2 threads.Compressing objects: 100% (3/3), done.Writing objects: 100% (10/10), 704 bytes | 0 bytes/s, done.Total 10 (delta 0), reused 0 (delta 0)To github.com:Ekimin/AlgoliaSearch.git 74a7280..978b221 master -&gt; master 查看远程分支123E:\\IDEA\\AlgoliaSearch&gt;git remote -vorigin git@github.com:Ekimin/AlgoliaSearch.git (fetch)origin git@github.com:Ekimin/AlgoliaSearch.git (push) 参考 在GitHub上管理项目 Git版本控制软件结合GitHub从入门到精通常用命令学习手册 gitignore文件 廖雪峰Git教程 错误汇总git在push的时候出现insufficient permission for adding an object错误http://blog.csdn.net/yujunf/article/details/7595231","tags":[{"name":"Github","slug":"Github","permalink":"https://wentuotuo.com/tags/Github/"},{"name":"Git","slug":"Git","permalink":"https://wentuotuo.com/tags/Git/"}]},{"title":"Java实现AES加密解密","date":"2017-02-24T02:22:51.000Z","path":"2017/02/24/Java/AES-encrypt-java/","text":"AES是一个对称分组密码算法，由美国国家标准技术研究所在2001年发布，旨在取代DES成为广泛使用的标准。 本文记录了Java实现AES算法进行加密解密，实际测试时还用到了Base64进行变换，以便于存储。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596package com.wentuotuo.aes;import sun.misc.BASE64Decoder;import sun.misc.BASE64Encoder;import javax.crypto.*;import java.security.InvalidKeyException;import java.security.NoSuchAlgorithmException;import java.security.Security;/** * Created by Ekimin on 2017/2/23. * UniTest */public class AESMethod &#123; //KeyGenerator 提供对称密钥生成器的功能，支持各种算法 private KeyGenerator keygen; //SecretKey 负责保存对称密钥 private SecretKey deskey; //Cipher负责完成加密或解密工作 private Cipher c; //该字节数组负责保存加密的结果 private byte[] cipherByte; public AESMethod() throws NoSuchAlgorithmException, NoSuchPaddingException&#123; Security.addProvider(new com.sun.crypto.provider.SunJCE()); //实例化支持DES算法的密钥生成器(算法名称命名需按规定，否则抛出异常) keygen = KeyGenerator.getInstance(\"AES\"); //生成密钥 deskey = keygen.generateKey(); //生成Cipher对象,指定其支持的DES算法 c = Cipher.getInstance(\"AES\"); &#125; /** * 对字符串加密 * * @param str * @return * @throws InvalidKeyException * @throws IllegalBlockSizeException * @throws BadPaddingException */ public byte[] Encrytor(String str) throws InvalidKeyException, IllegalBlockSizeException, BadPaddingException &#123; // 根据密钥，对Cipher对象进行初始化，ENCRYPT_MODE表示加密模式 c.init(Cipher.ENCRYPT_MODE, deskey); byte[] src = str.getBytes(); // 加密，结果保存进cipherByte cipherByte = c.doFinal(src); return cipherByte; &#125; /** * 对字符串解密 * * @param buff * @return * @throws InvalidKeyException * @throws IllegalBlockSizeException * @throws BadPaddingException */ public byte[] Decryptor(byte[] buff) throws InvalidKeyException, IllegalBlockSizeException, BadPaddingException &#123; // 根据密钥，对Cipher对象进行初始化，DECRYPT_MODE表示加密模式 c.init(Cipher.DECRYPT_MODE, deskey); cipherByte = c.doFinal(buff); return cipherByte; &#125; /** * @param args * @throws NoSuchPaddingException * @throws NoSuchAlgorithmException * @throws BadPaddingException * @throws IllegalBlockSizeException * @throws InvalidKeyException */ public static void main(String[] args) throws Exception &#123; AESMethod de1 = new AESMethod(); String msg =\"怕是要翻水水\"; byte[] encontent = de1.Encrytor(msg); System.out.println(\"明文是:\" + msg); System.out.println(\"加密后:\" + encontent); BASE64Encoder base64Encoder = new BASE64Encoder(); BASE64Decoder base64Decoder = new BASE64Decoder(); String base64 = base64Encoder.encode(encontent); System.out.println(\"转为base64后:\" + base64); byte[] rawCode = base64Decoder.decodeBuffer(base64); System.out.println(\"base64还原:\" + rawCode); byte[] decontent = de1.Decryptor(rawCode); System.out.println(\"解密后:\" + new String(decontent)); &#125;&#125; 测试结果 12345明文是:怕是要翻水水加密后:[B@a3a7a74转为base64后:ldQQ3iZzKBfUJ8o2ogQHxNcWfGvB1ddZja/+brSAx+A=base64还原:[B@7482384a解密后:怕是要翻水水 C语言实现的AES加密","tags":[{"name":"Java","slug":"Java","permalink":"https://wentuotuo.com/tags/Java/"},{"name":"AES","slug":"AES","permalink":"https://wentuotuo.com/tags/AES/"},{"name":"加密","slug":"加密","permalink":"https://wentuotuo.com/tags/加密/"}]},{"title":"用 Hexo 搭建个人博客","date":"2017-02-05T03:55:13.000Z","path":"2017/02/05/博客/use-hexo-siteup-personal-blog/","text":"目录： Hexo 博客原理 Hexo + Github 搭建个人博客 Hexo + VPS 搭建个人博客 博客备份和还原 主题优化 Hexo 博客原理Hexo简介Hexo 是一个简单地、轻量地、基于Node的一个静态博客框架，可以将支持的类型的文件转换成静态Web页面（html+css+JavaScript），hexo是不支持动态页面的（如jsp等）。下面是一张架构图： 大致流程：将 *.md 渲染成静态文件，然后Git推送到服务器的repository,服务器再通过 git-hooks 同步网站根目录。 搭建流程了解了原理，不难理解 Hexo 博客的搭建流程，大致以下几步。 服务器环境搭建，包括安装 Git 、Nginx配置 、创建 git 用户 。 本地 Hexo 初始化， 包括安装 NodeJS 、Hexo-cli, 生成本地静态网站 使用Git自动化部署发布博客 注：如果使用 Github 作为远程博客仓库，那么第一步就省了，因为 Github 的程序员已经帮我们做好了。 Hexo + github 搭建个人博客使用 Github 作为远程博客仓库优势多多，首先繁琐的服务器环境搭建不用我们操心了，而且也不用担心服务器挂掉，当然免费也是一项大优势。具体搭建过程参考本人另一篇博文：传送门 Hexo + VPS 搭建个人博客如果你有个人VPS，想把博客搭建到自己的服务器上，那么在上面步骤之前还需要在自己服务器上部署一些环境 本文测试环境：VPS：阿里云香港服务器一台系统：CentOs 7 安装 Git终端直接输入 git 查看是否安装有（默认CentOs 会自带git），如果没有，那么先安装 git。 1yum install git 安装 NodeJS根据你的VPS操作系统选择安装不同的版本，官方安装文档：传送门 我的OS是CentOs的，所以我选择 ArchLinux，然后里面定位到CentOs的安装命令： 12curl --silent --location https://rpm.nodesource.com/setup_6.x | bash -yum install nodejs 安装 hexo1[root@iZj6c2vq0s1w6wkap2geanZ blog.git]# npm install -g hexo 新建 git 用户虽然用 root 也能完成，但是为了安全起见，我们还是应该新建一个 git 用户来专门进行博客的管理，而不是全部事情都丢给 root。 查看系统内是否已经有 git 用户 1# cat /etc/passwd 新建 git 用户新建一个名叫 git 的用户，如果之前已经建立了，则跳过此命令1adduser git 给 git 用户添加 sudo 权限12chmod 740 /etc/sudoersvim /etc/sudoers 定位到以下内容：12## Allow root to run any commands anywhereroot ALL=(ALL) ALL 然后在下面新增一行: 1git ALL=(ALL) ALL 添加后效果如图： 保存编辑后退出。 PS：如果不熟悉VI或者VIM的使用，参考Linux vi/vim编辑器常用命令与用法总结 别忘了把文件权限改回去（还是为了安全）： 1chmod 400 /etc/sudoers 给 git 用户设置密码1sudo passwd git #该命令执行后输入两次要设置的密码 创建证书登录把自己电脑的公钥，也就是 ~/.ssh/id_rsa.pub 文件里的内容添加到服务器的 /home/git/.ssh/authorized_keys 文件中，添加公钥之后可以防止每次 push 都输入密码 例如，我的Windows电脑里面的id_rsa.pub文件存放在：如果你本地机器是Linux系统，那么该文件路径应该在： 1~/.ssh/ #当前用户主目录下的.ssh文件夹中 如果你发现并没有id_rsa.pub文件，那么说明之前没有生成过，请参考 生成SSH Key 服务器中/home/git/.ssh/authorized_keys文件在这里：12345678910111213[root@iZj6c2vq0s1w6wkap2geanZ git]# cd /home/git[root@iZj6c2vq0s1w6wkap2geanZ git]# ls -altotal 24drwx------ 3 git git 4096 Nov 18 10:26 .drwxr-xr-x. 5 root root 4096 Nov 21 16:15 ..-rw-r--r-- 1 git git 18 Oct 16 2014 .bash_logout-rw-r--r-- 1 git git 176 Oct 16 2014 .bash_profile-rw-r--r-- 1 git git 124 Oct 16 2014 .bashrcdrwxr-xr-x 2 root root 4096 Nov 18 10:28 .ssh[root@iZj6c2vq0s1w6wkap2geanZ git]# cd .ssh[root@iZj6c2vq0s1w6wkap2geanZ .ssh]# lltotal 4-rw-r--r-- 1 root root 404 Nov 18 10:27 authorized_keys 将你本机的公钥添加到上面authorized_keys就可以了，多个key换行。 设置 VPS 的 ssh 端口1[root@iZj6c2vq0s1w6wkap2geanZ hexo]# vim /etc/ssh/sshd_config 1Port 22 安装配置 Nginx安装 Nginx1[root@iZj6c2vq0s1w6wkap2geanZ nginx]# yum install nginx 配置 Nginx 删除nginx虚拟主机配置文件 1[root@iZj6c2vq0s1w6wkap2geanZ conf.d]# rm -rf /etc/nginx/conf.d/* 新建 /etc/nginx/conf.d/git.conf 文件，将以下内容添加到其中 12345678server &#123; root /var/www/hexo; #网站根目录 index index.html index.htm; server_name www.wentuotuo.com; #你的域名 location / &#123; try_files $uri $uri/ /index.html; &#125;&#125; 修改nginx配置文件 将/etc/nginx/nginx.conf中的user值修改为 git并新增：12include /etc/nginx/sites-available/*.conf;include /var/www/*.conf; 添加后配置文件如图：（红色方框内是新增内容） 测试配置是否正确 123[root@iZj6c2vq0s1w6wkap2geanZ blog.git]# nginx -tnginx: the configuration file /etc/nginx/nginx.conf syntax is oknginx: configuration file /etc/nginx/nginx.conf test is successful 配置防火墙 1[root@iZj6c2vq0s1w6wkap2geanZ blog.git]# iptables -I INPUT -p tcp --dport 80 -j ACCEPT 启动 nginx123[root@iZj6c2vq0s1w6wkap2geanZ blog.git]# service nginx reload[root@iZj6c2vq0s1w6wkap2geanZ blog.git]# /etc/init.d/nginx startStarting nginx: [ OK ] 创建博客仓库此处切换到 git 用户操作1[root@iZj6c2vq0s1w6wkap2geanZ .ssh]# su git 创建放仓库的目录12345678910[git@iZj6c2vq0s1w6wkap2geanZ var]$ sudo mkdir /var/www/blogWe trust you have received the usual lecture from the local SystemAdministrator. It usually boils down to these three things: #1) Respect the privacy of others. #2) Think before you type. #3) With great power comes great responsibility.[sudo] password for git: 这里有提示信息，可以忽视，输入前面设置的git用户的密码完成目录创建。目录路径可以自行改变，但是要保证git用户有相应权限。 创建一个裸仓库 blog123[git@iZj6c2vq0s1w6wkap2geanZ blog]$ sudo git init --bare blog.git[sudo] password for git:Initialized empty Git repository in /var/www/blog/blog.git/ 这样就创建了一个叫 blog 的裸仓库。–bare 参数是告诉 Git 创建一个裸仓库，裸仓库没有工作区，我们不会在裸仓库上进行操作，它只为共享而存在。 配置 git hooks参考资料：自定义 Git - Git 钩子 我们这里要使用的是 post-receive 的 hook，这个 hook 会在整个 git 操作过程完结以后被运行。 新建 post-receive 文件 在 /var/www/blog/blog.git/hook/ 目录下新建 post-receive 文件： 12[git@iZj6c2vq0s1w6wkap2geanZ hooks]$ cd /var/www/blog/blog.git/hooks/[git@iZj6c2vq0s1w6wkap2geanZ hooks]$ sudo vim post-receive 在新建的文件中输入以下信息并保存： 12345678#!/bin/bashGIT_REPO=/var/www/blog/blog.git #换成你部署静态网页的git仓库TMP_GIT_CLONE=/tmp/HexoBlog #临时文件目录PUBLIC_WWW=/var/www/hexo #网站发布目录，即实际的网站目录，里面包含index.html等网站内容rm -rf $&#123;TMP_GIT_CLONE&#125;git clone $GIT_REPO $TMP_GIT_CLONErm -rf $&#123;PUBLIC_WWW&#125;/*cp -rf $&#123;TMP_GIT_CLONE&#125;/* $&#123;PUBLIC_WWW&#125; 给post-receive 文件添加执行权限 1[git@iZj6c2vq0s1w6wkap2geanZ hooks]$ sudo chmod +x post-receive 其他配置改变 blog.git 拥有者为 git 用户12[git@iZj6c2vq0s1w6wkap2geanZ hooks]$ cd /var/www/blog/[git@iZj6c2vq0s1w6wkap2geanZ blog]$ sudo chown -R git:git blog.git 改变 hexo 目录拥有者为 git 用户12[git@iZj6c2vq0s1w6wkap2geanZ ~]$ cd /var/www/[git@iZj6c2vq0s1w6wkap2geanZ www]$ sudo chown -R git:git hexo 禁止 git 用户登录 shell为了安全考虑，在配置好上面信息以后，禁止git用户登录shell。 cat /etc/passwd 查看系统用户信息，找到git用户哪一行。1[git@iZj6c2vq0s1w6wkap2geanZ blog]$ cat /etc/passwd 比如我的机器上是：git:x:500:500::/home/git:/bin/bash 将其改为：git:x:500:500::/home/git:/usr/bin/git-shell 这样 git 用户可以正常使用 git-shell 但是不能使用bin/bash, 也就不能登录shell了。 发布博客在站点_config.yml 中配置deploy信息。 1234deploy: type: git repository: git@wentuotuo.com:/var/www/blog/blog.git branch: master repository换成你的VPS上博客仓库路径 用git进行博客备份和还原博客备份博客还原（在新环境中继续撰写博客） 安装 git、nodejs、hexo环境（同上） 克隆博客仓库 git clone [你的仓库URL] 切换到源码分支（如果源码分支是默认分支，那么克隆过后会默认处于该分支下，不需要再手动切换） git checkout [你的分支名字] 安装npm hexo 本地环境 123456npm install hexo --save #安装hexo环境到本目录npm install #安装npm 环境到本目录,该步骤不做的话可能会出现hexo generate过后缺少文件（如index页面）npm install hexo-deployer-git #hexo通过git发布网页的插件npm install hexo-algolia --save #使用algolia搜索的还需要安装此插件#...其他插件安装 环境恢复成功，可以使用hexo g -d 发布博客了","tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://wentuotuo.com/tags/Hexo/"},{"name":"博客","slug":"博客","permalink":"https://wentuotuo.com/tags/博客/"},{"name":"Github","slug":"Github","permalink":"https://wentuotuo.com/tags/Github/"}]},{"title":"IntelliJ IDEA 笔记","date":"2017-01-16T06:13:57.000Z","path":"2017/01/16/工具/IntelliJ-IDEA-tutorial/","text":"本文记录了IDEA的使用配置和遇到的问题，方便后面查询 IDEA 集成SVN 环境： OS：Windows 10 (64位) IDEA版本：IntelliJ IDEA 2016.3.4 Build #IU-163.12024.16, built on January 31, 2017 下载安装 SVN官网下载SVN并安装。 注意：安装时需要选择安装command line client tools, 默认这一项是不安装的。如果不安装，那么后面找不到svn.exe这个文件 在IDEA中配置SVN File-settings-subversion, 勾选Use command line client，选择刚刚安装的SVN中的svn.exe。(如果在bin下找不到这个文件，返回上一步检查安装的时候是否选择安装了command line client tool) 乱码问题IDEA乱码一般以下几类，按照如下设置后基本都可以解决 全局设置打开File-Setting, 找到File Encodings这个选项，把encoding设置成你工程的编码即可，一般是UTF-8。也可以在右下角快捷改变当前文件的编码。改变之后会提示你reload文件。 控制台乱码 执行main函数时乱码 同样是打开setting，找到 Build,Execution,Deployment &gt; Compiler &gt; Java Compiler， 设置 Additional command line parameters选项为 -encoding utf-8，然后rebuild下，重新运行 运行tomcat等容器时乱码 打开Run/Debug Configuration,选择你的tomcat 然后在 Server &gt; VM options 设置为 -Dfile.encoding=UTF-8 ，重启tomcat 如果上面不管用，可以尝试下面方法修改配置文件打开IDEA安装目录找到 idea.exe.vmoptions （64位为 idea64.exe.vmoptions ）文件， 在文件末尾加上一行 -Dfile.encoding=UTF-8然后重启IDEA，一般问题都可以解决 IDEA 激活激活服务器","tags":[{"name":"乱码","slug":"乱码","permalink":"https://wentuotuo.com/tags/乱码/"},{"name":"IDEA","slug":"IDEA","permalink":"https://wentuotuo.com/tags/IDEA/"}]},{"title":"Maven学习笔记","date":"2017-01-16T06:13:57.000Z","path":"2017/01/16/工具/Maven-tutorial/","text":"Maven 学习笔记常用命令Maven 命令基本格式12mvn &lt;plugin-prefix&gt;:&lt;goal&gt; -D&lt;属性名&gt;=&lt;属性值&gt;mvn &lt;phase1&gt; &lt;phase2&gt; ... archetype插件命令 mvn archetype:generate 使用指定原型创建一个 Maven 项目。 属性 interactiveMode=true/false 是否交互模式，默认true 属性 groupId 属性 artifactId 属性 package 属性 archetypeAtifactId 指定建立项目使用的模板，如：maven-archetype-webapp mvn archetype:create-from-project 使用已有项目创建一个 Maven 项目。 mvn archetype:crawl 从仓库中检索原型。 mvn archetype:generate -DinteractiveMode=false -DgroupId=com.wentuotuo -DartifactId=testMaven -Dpackage=com.wentuotuo.testmaven 上面命令会在当前目录创建一个名叫testMaven的项目 编译 mvn compile 执行 mvn exec:java -Dexec.mainClass=”com.wentuotuo.testMaven.App” Maven 项目目录约定 源代码：./src/main/java/ 资源文件： ./src/main/resources/ 测试代码： ./src/test/ 编译成的class文件: ./target/classes/ 项目整个打包的jar文件： ./target/ GroupId 是项目组织唯一的标识符，实际对应JAVA的包的结构，是main目录里java的目录结构,比如 com.wentuotuo ArtifactId 是项目的唯一的标识符，实际对应项目的名称，就是项目根目录的名称 Maven 生命周期clean生命周期 pre-clean 在构建之前进行预清理 clean 执行清理 post-clean 最后清理 mvn post-clean该命令会清理项目编译过程中生成的文件，执行后testMaven中只留下src和pom.xml default生命周期 compile 编译项目 test 单元测试 package 打包项目 install 安装到本地仓库 deploy 部署到远程仓库当执行 mvn install 时，将会先执行install之前的3个阶段，完成后再执行install。这也是maven生命周期的重要特性。site生命周期 pre-site 生成站点之前做验证 site 生成站点 post-site 生成站点之后做验证 site-deploy 发布站点到远程服务器 mvn post-site该命令会在target目录下生成一个site子目录，打开其中index.html就可以看到生成的站点 生命周期绑定pom.xml 见最下面。主要关注节点中exec插件的配置。 mvn compile执行该条命令时，不仅仅会执行编译，还会执行exec:java -Dexec.mainClass=”com.wentuotuo.testMaven.App” Maven 资源库 (repository)本地资源库通过 Maven 安装目录下的 conf\\setting.xml 或者 用户 home 目录下的 m2\\setting.xml 文件中的 元素进行设置，默认本地仓库在 ${user.home}/.m2/repository。1&lt;localRepository&gt;E:\\Config\\Maven\\repository&lt;/localRepository&gt; 例如上面，我在我用户目录下的 m2\\setting.xml 文件中设置了本地仓库地址 远程资源库12345678&lt;!-- 远程资源库 --&gt; &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;public&lt;/id&gt; &lt;name&gt;Public Repository&lt;/name&gt; &lt;url&gt;http://yourhost:8081/nexus/content/groups/public/&lt;/url&gt; &lt;/repository&gt; &lt;/repositories&gt; 当 Maven 需要某个插件或者jar包时，总是按照 本地仓库 -&gt; 远程仓库 -&gt; 中央仓库的顺序去寻找。并且从远程和中央仓库下载的插件会保存在本地，下次引用的时候就不需要重新下载了。 pom.xml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.wentuotuo&lt;/groupId&gt; &lt;!-- 项目开发者的域名 --&gt; &lt;artifactId&gt;testMaven&lt;/artifactId&gt; &lt;!-- 项目名字 --&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;!-- 指定项目打包的类型,默认jar --&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;!-- 指定项目的版本 --&gt; &lt;name&gt;mavenQs&lt;/name&gt; &lt;url&gt;http://maven.apache.org&lt;/url&gt; &lt;!-- 定义项目使用的License --&gt; &lt;licenses&gt; &lt;license&gt; &lt;name&gt;Apache 2&lt;/name&gt; &lt;url&gt;http://www.apache.org/licenses/LICENSE-2.0.txt&lt;/url&gt; &lt;distribution&gt;repo&lt;/distribution&gt; &lt;comments&gt;A business-freiendly OSS license&lt;/comments&gt; &lt;/license&gt; &lt;/licenses&gt; &lt;!-- 声明该项目所属的组织 --&gt; &lt;organization&gt; &lt;name&gt;Ekimin&lt;/name&gt; &lt;url&gt;ekimin.github.io&lt;/url&gt; &lt;/organization&gt; &lt;!-- 声明项目的开发者 --&gt; &lt;developers&gt; &lt;developer&gt; &lt;id&gt;ymhe&lt;/id&gt; &lt;name&gt;ymhe&lt;/name&gt; &lt;email&gt;youremail@gmail.com&lt;/email&gt; &lt;url&gt;wentuotuo.com&lt;/url&gt; &lt;organization&gt;Ekimin&lt;/organization&gt; &lt;!-- 声明开发者角色 --&gt; &lt;roles&gt; &lt;role&gt;developer&lt;/role&gt; &lt;/roles&gt; &lt;timezone&gt;+8&lt;/timezone&gt; &lt;/developer&gt; &lt;/developers&gt; &lt;!-- 声明对项目有贡献的人 --&gt; &lt;contributors&gt; &lt;contributor&gt; &lt;name&gt;george&lt;/name&gt; &lt;email&gt;youremail@gmail.com&lt;/email&gt; &lt;url&gt;wentuotuo.com&lt;/url&gt; &lt;organization&gt;Ekimin&lt;/organization&gt; &lt;roles&gt; &lt;role&gt;developer&lt;/role&gt; &lt;/roles&gt; &lt;/contributor&gt; &lt;/contributors&gt; &lt;!-- 自定义属性 --&gt; &lt;properties&gt; &lt;spring.version&gt;4.0.2.RELEASE&lt;/spring.version&gt; &lt;log4j.version&gt;1.2.17&lt;/log4j.version&gt; &lt;myproperty&gt;testProperty&lt;/myproperty&gt; &lt;/properties&gt; &lt;build&gt; &lt;!-- 插件配置 --&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.codehaus.mojo&lt;/groupId&gt; &lt;artifactId&gt;exec-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.5.0&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;!-- 指定绑定到compile阶段 --&gt; &lt;phase&gt;compile&lt;/phase&gt; &lt;!-- 指定目标,这里goal就相当于mvn exec:java中的java --&gt; &lt;goals&gt; &lt;goal&gt;java&lt;/goal&gt; &lt;/goals&gt; &lt;!-- 指定插件参数，即是-D后面的参数 --&gt; &lt;configuration&gt; &lt;mainClass&gt;com.wentuotuo.testMaven.App&lt;/mainClass&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;!-- 定义资源文件夹 --&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/java&lt;/directory&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;/build&gt; &lt;!-- 远程资源库 --&gt; &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;public&lt;/id&gt; &lt;name&gt;Public Repository&lt;/name&gt; &lt;url&gt;http://yourhost:8081/nexus/content/groups/public/&lt;/url&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;!-- 项目依赖 --&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;3.8.1&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; setting.xml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;!--Licensed to the Apache Software Foundation (ASF) under oneor more contributor license agreements. See the NOTICE filedistributed with this work for additional informationregarding copyright ownership. The ASF licenses this fileto you under the Apache License, Version 2.0 (the\"License\"); you may not use this file except in compliancewith the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0Unless required by applicable law or agreed to in writing,software distributed under the License is distributed on an\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANYKIND, either express or implied. See the License for thespecific language governing permissions and limitationsunder the License.--&gt;&lt;!-- | This is the configuration file for Maven. It can be specified at two levels: | | 1. User Level. This settings.xml file provides configuration for a single user, | and is normally provided in $&#123;user.home&#125;/.m2/settings.xml. | | NOTE: This location can be overridden with the CLI option: | | -s /path/to/user/settings.xml | | 2. Global Level. This settings.xml file provides configuration for all Maven | users on a machine (assuming they're all using the same Maven | installation). It's normally provided in | $&#123;maven.home&#125;/conf/settings.xml. | | NOTE: This location can be overridden with the CLI option: | | -gs /path/to/global/settings.xml | | The sections in this sample file are intended to give you a running start at | getting the most out of your Maven installation. Where appropriate, the default | values (values used when the setting is not specified) are provided. | |--&gt;&lt;settings xmlns=\"http://maven.apache.org/SETTINGS/1.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/SETTINGS/1.0.0 http://maven.apache.org/xsd/settings-1.0.0.xsd\"&gt; &lt;!-- localRepository | The path to the local repository maven will use to store artifacts. | | Default: $&#123;user.home&#125;/.m2/repository --&gt; &lt;localRepository&gt;E:\\Config\\Maven\\repository&lt;/localRepository&gt; &lt;!-- interactiveMode | This will determine whether maven prompts you when it needs input. If set to false, | maven will use a sensible default value, perhaps based on some other setting, for | the parameter in question. | | Default: true &lt;interactiveMode&gt;true&lt;/interactiveMode&gt; --&gt; &lt;!-- offline | Determines whether maven should attempt to connect to the network when executing a build. | This will have an effect on artifact downloads, artifact deployment, and others. | | Default: false &lt;offline&gt;false&lt;/offline&gt; --&gt; &lt;!-- pluginGroups | This is a list of additional group identifiers that will be searched when resolving plugins by their prefix, i.e. | when invoking a command line like \"mvn prefix:goal\". Maven will automatically add the group identifiers | \"org.apache.maven.plugins\" and \"org.codehaus.mojo\" if these are not already contained in the list. |--&gt; &lt;pluginGroups&gt; &lt;!-- pluginGroup | Specifies a further group identifier to use for plugin lookup. &lt;pluginGroup&gt;com.your.plugins&lt;/pluginGroup&gt; --&gt; &lt;/pluginGroups&gt; &lt;!-- proxies | This is a list of proxies which can be used on this machine to connect to the network. | Unless otherwise specified (by system property or command-line switch), the first proxy | specification in this list marked as active will be used. |--&gt; &lt;proxies&gt; &lt;!-- proxy | Specification for one proxy, to be used in connecting to the network. | &lt;proxy&gt; &lt;id&gt;optional&lt;/id&gt; &lt;active&gt;true&lt;/active&gt; &lt;protocol&gt;http&lt;/protocol&gt; &lt;username&gt;proxyuser&lt;/username&gt; &lt;password&gt;proxypass&lt;/password&gt; &lt;host&gt;proxy.host.net&lt;/host&gt; &lt;port&gt;80&lt;/port&gt; &lt;nonProxyHosts&gt;local.net|some.host.com&lt;/nonProxyHosts&gt; &lt;/proxy&gt; --&gt; &lt;/proxies&gt; &lt;!-- servers | This is a list of authentication profiles, keyed by the server-id used within the system. | Authentication profiles can be used whenever maven must make a connection to a remote server. |--&gt; &lt;servers&gt; &lt;!-- server | Specifies the authentication information to use when connecting to a particular server, identified by | a unique name within the system (referred to by the 'id' attribute below). | | NOTE: You should either specify username/password OR privateKey/passphrase, since these pairings are | used together. | --&gt; &lt;server&gt; &lt;id&gt;public&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;admin123&lt;/password&gt; &lt;/server&gt; &lt;!-- Another sample, using keys to authenticate. &lt;server&gt; &lt;id&gt;siteServer&lt;/id&gt; &lt;privateKey&gt;/path/to/private/key&lt;/privateKey&gt; &lt;passphrase&gt;optional; leave empty if not used.&lt;/passphrase&gt; &lt;/server&gt; --&gt; &lt;/servers&gt; &lt;!-- mirrors | This is a list of mirrors to be used in downloading artifacts from remote repositories. | | It works like this: a POM may declare a repository to use in resolving certain artifacts. | However, this repository may have problems with heavy traffic at times, so people have mirrored | it to several places. | | That repository definition will have a unique id, so we can create a mirror reference for that | repository, to be used as an alternate download site. The mirror site will be the preferred | server for that repository. |--&gt; &lt;mirrors&gt; &lt;!-- mirror | Specifies a repository mirror site to use instead of a given repository. The repository that | this mirror serves has an ID that matches the mirrorOf element of this mirror. IDs are used | for inheritance and direct lookup purposes, and must be unique across the set of mirrors. | --&gt; &lt;mirror&gt; &lt;id&gt;mirrorId&lt;/id&gt; &lt;mirrorOf&gt;*&lt;/mirrorOf&gt; &lt;name&gt;WTT mirror&lt;/name&gt; &lt;url&gt;http://yourhost:8081/nexus/content/groups/public/&lt;/url&gt; &lt;/mirror&gt; &lt;/mirrors&gt; &lt;!-- profiles | This is a list of profiles which can be activated in a variety of ways, and which can modify | the build process. Profiles provided in the settings.xml are intended to provide local machine- | specific paths and repository locations which allow the build to work in the local environment. | | For example, if you have an integration testing plugin - like cactus - that needs to know where | your Tomcat instance is installed, you can provide a variable here such that the variable is | dereferenced during the build process to configure the cactus plugin. | | As noted above, profiles can be activated in a variety of ways. One way - the activeProfiles | section of this document (settings.xml) - will be discussed later. Another way essentially | relies on the detection of a system property, either matching a particular value for the property, | or merely testing its existence. Profiles can also be activated by JDK version prefix, where a | value of '1.4' might activate a profile when the build is executed on a JDK version of '1.4.2_07'. | Finally, the list of active profiles can be specified directly from the command line. | | NOTE: For profiles defined in the settings.xml, you are restricted to specifying only artifact | repositories, plugin repositories, and free-form properties to be used as configuration | variables for plugins in the POM. | |--&gt; &lt;profiles&gt; &lt;!-- profile | Specifies a set of introductions to the build process, to be activated using one or more of the | mechanisms described above. For inheritance purposes, and to activate profiles via &lt;activatedProfiles/&gt; | or the command line, profiles have to have an ID that is unique. | | An encouraged best practice for profile identification is to use a consistent naming convention | for profiles, such as 'env-dev', 'env-test', 'env-production', 'user-jdcasey', 'user-brett', etc. | This will make it more intuitive to understand what the set of introduced profiles is attempting | to accomplish, particularly when you only have a list of profile id's for debug. | | This profile example uses the JDK version to trigger activation, and provides a JDK-specific repo. --&gt; &lt;profile&gt; &lt;id&gt;nexus&lt;/id&gt; &lt;!-- &lt;activation&gt; &lt;jdk&gt;1.4&lt;/jdk&gt; &lt;/activation&gt; --&gt; &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;public&lt;/id&gt; &lt;name&gt;WTT repo&lt;/name&gt; &lt;url&gt;http://wttrepo&lt;/url&gt;&lt;!-- 假的地址 --&gt; &lt;layout&gt;default&lt;/layout&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;/profile&gt; &lt;!-- | Here is another profile, activated by the system property 'target-env' with a value of 'dev', | which provides a specific path to the Tomcat instance. To use this, your plugin configuration | might hypothetically look like: | | ... | &lt;plugin&gt; | &lt;groupId&gt;org.myco.myplugins&lt;/groupId&gt; | &lt;artifactId&gt;myplugin&lt;/artifactId&gt; | | &lt;configuration&gt; | &lt;tomcatLocation&gt;$&#123;tomcatPath&#125;&lt;/tomcatLocation&gt; | &lt;/configuration&gt; | &lt;/plugin&gt; | ... | | NOTE: If you just wanted to inject this configuration whenever someone set 'target-env' to | anything, you could just leave off the &lt;value/&gt; inside the activation-property. | &lt;profile&gt; &lt;id&gt;env-dev&lt;/id&gt; &lt;activation&gt; &lt;property&gt; &lt;name&gt;target-env&lt;/name&gt; &lt;value&gt;dev&lt;/value&gt; &lt;/property&gt; &lt;/activation&gt; &lt;properties&gt; &lt;tomcatPath&gt;/path/to/tomcat/instance&lt;/tomcatPath&gt; &lt;/properties&gt; &lt;/profile&gt; --&gt; &lt;/profiles&gt; &lt;!-- activeProfiles | List of profiles that are active for all builds. | --&gt; &lt;activeProfiles&gt; &lt;activeProfile&gt;nexus&lt;/activeProfile&gt; &lt;!-- &lt;activeProfile&gt;anotherAlwaysActiveProfile&lt;/activeProfile&gt; --&gt; &lt;/activeProfiles&gt;&lt;/settings&gt;","tags":[{"name":"Maven","slug":"Maven","permalink":"https://wentuotuo.com/tags/Maven/"}]},{"title":"Hbase新API Demo","date":"2016-12-22T14:34:08.000Z","path":"2016/12/22/大数据/demo-of-hbase-in-java-new-API-1.X/","text":"HBase 1.0版是一个稳定版本，可以用于生产环境，而对于0.98.x系列版本，HBase开发团队仍然会继续维护和开发。 下面是一个scan表操作的Demo 1234567891011121314151617 // 创建一个hbase用户 UserGroupInformation userGroupInformation = UserGroupInformation.createRemoteUser(\"hbase\"); User user = User.create(userGroupInformation); // 创建连接 Connection connection = null; Table table = null; //Admin admin = null; try &#123; connection = ConnectionFactory.createConnection(conf, user); table = connection.getTable(TableName.valueOf(tableName));// admin = connection.getAdmin(); ResultScanner resultScanner = HbaseCommons.scanTable(table); for (Result result : resultScanner) &#123; HbaseCommons.printResult(result); &#125;","tags":[{"name":"大数据","slug":"大数据","permalink":"https://wentuotuo.com/tags/大数据/"},{"name":"Hbase","slug":"Hbase","permalink":"https://wentuotuo.com/tags/Hbase/"}]},{"title":"CentOs安装配置SS+Chrome+SwitchyOmega配置","date":"2016-12-08T02:39:29.000Z","path":"2016/12/08/工具/centos-ss-chrome-omega/","text":"环境：服务器：阿里云香港云服务器一台系统：CentOs 7 第一步 安装Shadowsocks服务端安装ss123456789101112131415161718192021[root@iZj6c2vq0s1w6wkap2geanZ ~]# yum install python-setuptools &amp;&amp; easy_install pipLoaded plugins: securitybase | 3.7 kB 00:00 epel | 4.3 kB 00:00 epel/primary_db | 5.9 MB 00:05 extras | 3.4 kB 00:00 updates | 3.4 kB 00:00 updates/primary_db | 3.7 MB 00:03 Setting up Install ProcessPackage python-setuptools-0.6.10-3.el6.noarch already installed and latest versionNothing to doSearching for pipBest match: pip 7.1.0Adding pip 7.1.0 to easy-install.pth fileInstalling pip script to /usr/binInstalling pip2.6 script to /usr/binInstalling pip2 script to /usr/binUsing /usr/lib/python2.6/site-packagesProcessing dependencies for pipFinished processing dependencies for pip 12345678910[root@iZj6c2vq0s1w6wkap2geanZ ~]# pip install shadowsocks/usr/lib/python2.6/site-packages/pip/_vendor/requests/packages/urllib3/util/ssl_.py:90: InsecurePlatformWarning: A true SSLContext object is not available. This prevents urllib3 from configuring SSL appropriately and may cause certain SSL connections to fail. For more information, see https://urllib3.readthedocs.org/en/latest/security.html#insecureplatformwarning. InsecurePlatformWarningYou are using pip version 7.1.0, however version 9.0.1 is available.You should consider upgrading via the &apos;pip install --upgrade pip&apos; command.Collecting shadowsocks Downloading http://mirrors.aliyun.com/pypi/packages/02/1e/e3a5135255d06813aca6631da31768d44f63692480af3a1621818008eb4a/shadowsocks-2.8.2.tar.gzInstalling collected packages: shadowsocks Running setup.py install for shadowsocksSuccessfully installed shadowsocks-2.8.2 创建配置文件/etc/shadowsocks.json12[root@iZj6c2vq0s1w6wkap2geanZ ~]# touch /etc/shadowsocks.json[root@iZj6c2vq0s1w6wkap2geanZ ~]# vim /etc/shadowsocks.json 配置文件内容123456789&#123;&quot;server&quot;:&quot;47.90.56.123&quot;, #服务器地址&quot;server_port&quot;:443, #服务器端口&quot;local_address&quot;: &quot;127.0.0.1&quot;, #本地地址&quot;local_port&quot;:1080, #本地端口&quot;password&quot;:&quot;myPass&quot;, #用来加密的密码&quot;timeout&quot;:600, #超时时间&quot;method&quot;:&quot;rc4-md5&quot; #加密方法，可选择 “bf-cfb”, “aes-256-cfb”, “des-cfb”, “rc4″等。推荐rc4-md5，速度快&#125; 启动服务使用配置文件在后台运行shadowsocks服务1234[root@iZj6c2vq0s1w6wkap2geanZ ~]# ssserver -c /etc/shadowsocks.json -d startINFO: loading config from /etc/shadowsocks.json2016-12-08 10:49:54 INFO loading libcrypto from libcrypto.so.10started 无配置文件启动1ssserver -p 443 -k MyPass -m rc4-md5 -d start 停止服务123[root@iZj6c2vq0s1w6wkap2geanZ ~]# ssserver -c /etc/shadowsocks.json -d stopINFO: loading config from /etc/shadowsocks.jsonstopped 至此，服务器就安装好了 Chrome Omega配置 AutoProxy规则列表：https://raw.githubusercontent.com/gfwlist/gfwlist/master/gfwlist.txt","tags":[{"name":"Linux","slug":"Linux","permalink":"https://wentuotuo.com/tags/Linux/"},{"name":"ShadowSocks","slug":"ShadowSocks","permalink":"https://wentuotuo.com/tags/ShadowSocks/"},{"name":"SwithyOmega","slug":"SwithyOmega","permalink":"https://wentuotuo.com/tags/SwithyOmega/"},{"name":"翻墙","slug":"翻墙","permalink":"https://wentuotuo.com/tags/翻墙/"}]},{"title":"Aria2安装配置","date":"2016-12-07T15:31:31.000Z","path":"2016/12/07/工具/Aria2-tutorial/","text":"认识 Aria2Aria2 是一个轻量级多协议和多源 命令行 下载实用工具。它支持 HTTP / HTTPS, FTP, SFTP, bt 和 Metalink。通过内置 Aria2 可以操作 json - rpc 和 xml - rpc。对，Aria2 没有 GUI 图形界面，只有粗糙的命令行界面！但这也正是 Aria2 之轻快好省所在。 linux：下载 直接在软件仓库下载：123yum install aria2 --或apt-get aria2…… 在mint上用软件包管理器下载的aria2默认安装在 /usr/share/doc下。 也可以下载源码安装。 配置建立目录 /etc/software/aria2 用于放置配置文件的地方 /home/aria2/downloads 用于放下载的文件 新建文件 /etc/software/aria2/aria2.conf /etc/software/aria2/aria2.session /etc/software/aria2/Aria2.log 12345678desktop aria2 # pwd/etc/software/aria2desktop aria2 # lltotal 12drwxr-xr-x 2 root root 4096 7月 23 18:12 ./drwxr-xr-x 3 root root 4096 7月 23 18:11 ../-rw-r--r-- 1 root root 3846 7月 23 18:12 aria2.conf-rw-r--r-- 1 root root 0 7月 23 18:12 aria2.session 修改ari2.conf：（比较重要的是dir log input-file save-session四个属性）123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103## &apos;#&apos;开头为注释内容, 选项都有相应的注释说明, 根据需要修改 #### 被注释的选项填写的是默认值, 建议在需要修改时再取消注释 #### 文件保存相关 ### 文件的保存路径(可使用绝对路径或相对路径), 默认: 当前启动位置dir=/home/aria2/downloads# 日志文件保存路径log=/etc/software/aria2/Aria2.log# 启用磁盘缓存, 0为禁用缓存, 需1.16以上版本, 默认:16M#disk-cache=32M# 文件预分配方式, 能有效降低磁盘碎片, 默认:prealloc# 预分配所需时间: none &lt; falloc ? trunc &lt; prealloc# falloc和trunc则需要文件系统和内核支持# NTFS建议使用falloc, EXT3/4建议trunc, MAC 下需要注释此项file-allocation=trunc# 断点续传continue=true## 下载连接相关 ### 最大同时下载任务数, 运行时可修改, 默认:5max-concurrent-downloads=5# 同一服务器连接数, 添加时可指定, 默认:1max-connection-per-server=5# 最小文件分片大小, 添加时可指定, 取值范围1M -1024M, 默认:20M# 假定size=10M, 文件为20MiB 则使用两个来源下载; 文件为15MiB 则使用一个来源下载min-split-size=10M# 单个任务最大线程数, 添加时可指定, 默认:5split=5# 整体下载速度限制, 运行时可修改, 默认:0#max-overall-download-limit=0# 单个任务下载速度限制, 默认:0#max-download-limit=0# 整体上传速度限制, 运行时可修改, 默认:0#max-overall-upload-limit=0# 单个任务上传速度限制, 默认:0#max-upload-limit=0# 禁用IPv6, 默认:falsedisable-ipv6=true## 进度保存相关 ### 从会话文件中读取下载任务input-file=/etc/software/aria2/aria2.session# 在Aria2退出时保存`错误/未完成`的下载任务到会话文件save-session=/etc/software/aria2/aria2.session# 定时保存会话, 0为退出时才保存, 需1.16.1以上版本, 默认:0#save-session-interval=60## RPC相关设置 ### 启用RPC, 默认:falseenable-rpc=true# 允许所有来源, 默认:falserpc-allow-origin-all=true# 允许非外部访问, 默认:falserpc-listen-all=true# 事件轮询方式, 取值:[epoll, kqueue, port, poll, select], 不同系统默认值不同#event-poll=select# RPC监听端口, 端口被占用时可以修改, 默认:6800#rpc-listen-port=6800# 设置的RPC授权令牌, v1.18.4新增功能, 取代 --rpc-user 和 --rpc-passwd 选项#rpc-secret=&lt;TOKEN&gt;# 设置的RPC访问用户名, 此选项新版已废弃, 建议改用 --rpc-secret 选项#rpc-user=&lt;USER&gt;# 设置的RPC访问密码, 此选项新版已废弃, 建议改用 --rpc-secret 选项#rpc-passwd=&lt;PASSWD&gt;## BT/PT下载相关 ### 当下载的是一个种子(以.torrent结尾)时, 自动开始BT任务, 默认:true#follow-torrent=true# BT监听端口, 当端口被屏蔽时使用, 默认:6881-6999listen-port=51413# 单个种子最大连接数, 默认:55#bt-max-peers=55# 打开DHT功能, PT需要禁用, 默认:trueenable-dht=false# 打开IPv6 DHT功能, PT需要禁用#enable-dht6=false# DHT网络监听端口, 默认:6881-6999#dht-listen-port=6881-6999# 本地节点查找, PT需要禁用, 默认:false#bt-enable-lpd=false# 种子交换, PT需要禁用, 默认:trueenable-peer-exchange=false# 每个种子限速, 对少种的PT很有用, 默认:50K#bt-request-peer-speed-limit=50K# 客户端伪装, PT需要peer-id-prefix=-TR2770-user-agent=Transmission/2.77# 当种子的分享率达到这个数时, 自动停止做种, 0为一直做种, 默认:1.0seed-ratio=0# 强制保存会话, 即使任务已经完成, 默认:false# 较新的版本开启后会在任务完成后依然保留.aria2文件#force-save=false# BT校验相关, 默认:true#bt-hash-check-seed=true# 继续之前的BT任务时, 无需再次校验, 默认:falsebt-seed-unverified=true# 保存磁力链接元数据为种子文件(.torrent文件), 默认:falsebt-save-metadata=true 启动服务并指定aria2配置文件的路径12345desktop aria2 # aria2c --conf-path /etc/software/aria2/aria2.conf07/23 18:13:30 [WARN] Neither --rpc-secret nor a combination of --rpc-user and --rpc-passwd is set. This is insecure. It is extremely recommended to specify --rpc-secret with the adequate secrecy or now deprecated --rpc-user and --rpc-passwd.07/23 18:13:30 [NOTICE] IPv4 RPC: listening on TCP port 6800 Window基本上Window配置和linux差不多这里简单说下不同的地方 下载Aria2官方下载地址 配置新建文件 aria2.conf aria2.session Aria2.log HideRun.vbs 同样修改配置文件conf，指定好下载目录，session文件和log文件的地址 而后修改 HideRun.vbs，将 Aria2c.exe 与配置文件 Aria2.conf 链接，并实现无命令行启动。 那么日后打开 Aria2 就双击 HideRun.vbs 这个文件而不是双击 aria2c.exe。1CreateObject(&quot;WScript.Shell&quot;).Run &quot;D:\\Aria2\\aria2c.exe --conf-path=aria2.conf&quot;,0 将上面路径修改为你aria2c.exe的路径。到这里 Aria2 就配置好了，如果要添加开机自启动将 HideRun.vbs 的快捷方式拖入启动文件夹就 OK 了。 使用WebUI管理下载为了方便管理下载，我们可以使用网页来管理下载。 WebUI地址 http://aria2c.com/ 若提示RPC服务配置出错：JSON-RPC Path 默认为: http://localhost:6800/jsonrpchost: 指运行 Aria2 所在机器的 IP 或者名字port: 使用 –rpc-listen-port 选项设置的端口, 未设置则是 6800普通情况设置为: http://host:port/jsonrpc使用 –rpc-secret=xxxxxx 选项设置为: http://token:xxxxxx@host:port/jsonrpc使用 –rpc-user=user –rpc-passwd=pwd 选项设置为: http://user:pwd@host:port/jsonrpc 添加脚本迅雷离线Chrome Extension: ThunderLixianAssistantUserScript: ThunderLixianExporter 旋风离线UserScript: XuanFengExUserScript: LixianExporter 百度网盘Chrome Extension: BaiduExporterFirefox Addons: BaiduExporterUserScript: BaiduPanDownloadHelper 其他脚本Chrome Extension: 谷歌浏览器aria2插件 常见问题aria2 不能启动清空 aria2.session 内容，重新尝试启动。","tags":[{"name":"Aria2","slug":"Aria2","permalink":"https://wentuotuo.com/tags/Aria2/"}]},{"title":"在github上搭建hexo博客","date":"2016-10-13T09:47:25.000Z","path":"2016/10/13/博客/hexo-blog-based-on-github/","text":"本文介绍并记录了hexo博客的搭建过程 版本说明博客撰写时版本：hexo: 3.2.2node: 6.9.4 安装node.js官网下载最新node.js并安装。 安装Git官网下载最新 Git for Windows 并安装。Git for Windows 包含git bash 和 git ui两种，其中git bash 就能满足所有需求，git ui 只是多了一个图形界面，安装的时候可以选择不安装。 申请 Github 账号官网申请 github 账号生成 ssh key如果不执行这一步，那么在选择仓库地址的时候需要使用http协议，而且提交要输入github账号密码。如果配置了ssh则不需要 创建一个空的仓库建立与你用户名对应的仓库，仓库名必须为 your_user_name.github.io，比如我的仓库为 ekimin.github.io 安装 hexo任意目录下右键，选择 git bash。在bash中输入： 1npm install -g hexo 如果下载缓慢或失败，尝试VPN或者代理。 使用 hexo 创建博客初始化新建一个目录，如blog，在该目录下打开 git bash 进行以下操作： 1hexo init 初始化完成后，hexo会在当前目录生成一系列文件，这些就是博客的源码。 生成静态页面123hexo generate或者简写hexo g 完成后你会发现目录下多了一些目录和文件，这些就是 hexo 生成的静态页面相关文件。 本地测试博客启动一个本地服务来测试123hexo server或者hexo s 在浏览器中访问 localhost:4000 查看页面 发布到github 修改博客目录下 _config.yml 文件 （注意每一项冒号后都有一个空格）1234deploy: type: git #通过git部署 repository: https://github.com/Ekimin/Ekimin.github.io.git #git仓库地址，需要提前建立 （这里用的是http协议，部署的时候会提示你输入github的账号密码，如果配置了ssh则可以直接使用ssh地址，这种方式不用输入账号密码，比如：git@github.com:Ekimin/Ekimin.github.io.git） branch: master #分支 部署安装git部署插件 1npm install hexo-deployer-git --save 然后123hexo deploy或者hexo d 登录 ${yourname}.github.io 访问页面","tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://wentuotuo.com/tags/Hexo/"},{"name":"博客","slug":"博客","permalink":"https://wentuotuo.com/tags/博客/"}]},{"title":"Hive和Hbase的关系","date":"2016-09-25T09:44:18.000Z","path":"2016/09/25/大数据/relation-between-hive-and-hbase/","text":"导读 什么是Hive？ hive与hbase的关系 什么是Hive？Apache Hive数据仓库软件提供对存储在分布式中的大型数据集的查询和管理，它本身是建立在Apache Hadoop之上，主要提供以下功能： 它提供了一系列的工具，可用来对数据进行提取/转化/加载（ETL）； 是一种可以存储、查询和分析存储在HDFS（或者HBase）中的大规模数据的机制； 查询是通过MapReduce来完成的（并不是所有的查询都需要MapReduce来完成，比如select * from XXX就不需要； 在Hive0.11对类似select a,b from XXX的查询通过配置也可以不通过MapReduce来完成 上面的意思很明白了.这里再给他提炼一下： hive是一个数据仓库。 hive基于hadoop。总结为一句话：hive是基于hadoop的数据仓库。 那么上面“基于”如何理解： Hive是一种建立在Hadoop文件系统上的数据仓库架构，并对存储在HDFS中的数据进行分析和管理。（也就是说对存储在HDFS中的数据进行分析和管理，我们不想使用手工，我们建立一个工具把，那么这个工具就可以是hive） 那么，我们如何来分析和管理那些数据呢？ Hive定义了一种类似SQL的查询语言，被称为HQL，对于熟悉SQL的用户可以直接利用Hive来查询数据。同时，这个语言也允许熟悉 MapReduce 开发者们开发自定义的mappers和reducers来处理内建的mappers和reducers无法完成的复杂的分析工作。Hive可以允许用户编写自己定义的函数UDF，来在查询中使用。Hive中有3种UDF：User Defined Functions（UDF）、User Defined Aggregation Functions（UDAF）、User Defined Table Generating Functions（UDTF）。 今天，Hive已经是一个成功的Apache项目，很多组织把它用作一个通用的、可伸缩的数据处理平台。 当然，Hive和传统的关系型数据库有很大的区别，Hive将外部的任务解析成一个MapReduce可执行计划，而启动MapReduce是一个高延迟的一件事，每次提交任务和执行任务都需要消耗很多时间，这也就决定Hive只能处理一些高延迟的应用（如果你想处理低延迟的应用，你可以去考虑一下Hbase）。同时，由于设计的目标不一样，Hive目前还不支持事务；不能对表数据进行修改（不能更新、删除、插入；只能通过文件追加数据、重新导入数据）；不能对列建立索引（但是Hive支持索引的建立，但是不能提高Hive的查询速度。如果你想提高Hive的查询速度，请学习Hive的分区、桶的应用）。 hive与hbase的联系与区别共同点hbase与hive都是架构在hadoop之上的。都是用hadoop作为底层存储 不同点 Hive是建立在Hadoop之上为了减少MapReduce jobs编写工作的批处理系统，HBase是为了支持弥补Hadoop对实时操作的缺陷的项目 。 想象你在操作RMDB数据库，如果是全表扫描，就用Hive+Hadoop,如果是索引访问，就用HBase+Hadoop 。 Hive query就是MapReduce jobs可以从5分钟到数小时不止，HBase是非常高效的，肯定比Hive高效的多。 Hive本身不存储和计算数据，它完全依赖于HDFS和MapReduce，Hive中的表纯逻辑。 hive借用hadoop的MapReduce来完成一些hive中的命令的执行 hbase是物理表，不是逻辑表，提供一个超大的内存hash表，搜索引擎通过它来存储索引，方便查询操作。 hbase是列存储。 hdfs作为底层存储，hdfs是存放文件的系统，而Hbase负责组织文件。 hive需要用到hdfs存储文件，需要用到MapReduce计算框架。","tags":[{"name":"大数据","slug":"大数据","permalink":"https://wentuotuo.com/tags/大数据/"},{"name":"Hbase","slug":"Hbase","permalink":"https://wentuotuo.com/tags/Hbase/"},{"name":"Hive","slug":"Hive","permalink":"https://wentuotuo.com/tags/Hive/"}]},{"title":"Solr 6.4.1 搭建和使用教程","date":"2016-08-22T11:22:54.000Z","path":"2016/08/22/大数据/solr6-4-1-manual/","text":"Solr 搭建环境Solr：solr-6.4.1JDK：1.8.0_111tomcat：8.5.1 （8版本都支持）OS： CentOs 7 单例模式下部署Solr目录结构 solr6.4内嵌了jetty，不再需要tomcat作为容器启动，所以安装solr6.4.1非常简单：解压下载solr6.4.1到任意目录，然后cd 到 bin 目录下运行命令 12345[ymhe@iZj6c2vq0s1w6wkap2geanZ bin]$ ./solr startArchiving 1 old GC log files to /home/ymhe/software/solr-6.4.1/server/logs/archivedArchiving 1 console log files to /home/ymhe/software/solr-6.4.1/server/logs/archivedWaiting up to 180 seconds to see Solr running on port 8983 [\\] Started Solr server on port 8983 (pid=28125). Happy searching! 默认端口8983，现在访问浏览器地址 http://localhost:8983/solr 就可以访问。 solr 命令solr option [参数] solr start -p 8984 –使用指定的端口号启动solr服务 solr start -help 新建 Core 在solr-6.4.1/server/solr下，创建一个文件夹（名字自定义），这个文件夹就是一个core 123[ymhe@iZj6c2vq0s1w6wkap2geanZ solr]$ pwd/home/ymhe/software/solr-6.4.1/server/solr[ymhe@iZj6c2vq0s1w6wkap2geanZ solr]$ mkdir wtt_core solr-6.4.1/server/solr/configsets/basic_configs下的conf文件夹复制进来 123[ymhe@iZj6c2vq0s1w6wkap2geanZ basic_configs]$ pwd/home/ymhe/software/solr-6.4.1/server/solr/configsets/basic_configs[ymhe@iZj6c2vq0s1w6wkap2geanZ basic_configs]$ cp -r conf/ /home/ymhe/software/solr-6.4.1/server/solr/wtt_core/ 在sol界面上新建core，填入name和instancDir（第一步中建立的文件夹的名字，即核心的名字） 点击 Add Core, 添加完成后如图所示。 solrconfig.xml 配置123456789101112131415161718192021222324252627282930313233343536373839404142&lt;luceneMatchVersion&gt; 声明使用的lucene 的版本。&lt;lib&gt; 配置solr 用到的 jar包，具体语法示例中基本都有了。&lt;dataDir&gt;solrhome下core下的data 目录，可指定其它目录来存放所有索引数据。&lt;directoryFactory&gt; 索引文件的类型，默认solr.NRTCachingDirectoryFactory，这个文件类型包装了 solr.StandardDirectoryFactory 和小文件内存缓存的类型，来提供 NRT（near-real-time近实时）搜索性能。。&lt;indexConfig&gt; 主要索引相关配置： &lt;lockType&gt;文件锁的类型，默认 native，使用 NativeFSLockFactory 。 &lt;infoStream&gt;为了调试， Lucene提供了这个参数，如果是 true的话， IndexWriter 会像设置的文件中写入 debug信息。&lt;jmx&gt; 一般不需要设置具体可以查看 wiki文档http://wiki.apache.org/solr/SolrJmx&lt;updateHandler&gt; 更新的Handler ，默认DirectUpdateHandler2，主要配置如下： &lt;updateLog&gt;&lt;strname=\"dir\"&gt; 配置更新日志的存放位置 &lt;autoCommit&gt; 硬自动提交，可以配置 maxDocs即从上次提交后达到多少文档后会触发自动提交； maxTime时间限制； openSearcher ，如果设为false ，导致索引变化的最新提交，不需要重新打开 searcher就能看到这些变化，默认 false。 &lt;autoSoftCommit&gt;软自动提交，与前面的 &lt;autuCommit&gt; 相似，但是它只是让这些变化能够看到，并不保证这些变化会同步到磁盘上。这种方法比硬提交要快，而且更接近实时更友好。&lt;query&gt; 配置检索词相关参数以及缓存配置参数。 &lt;maxBooleanClauses&gt;每个 BooleanQuery 中最大BooleanClauses 的数目，默认 1024。 &lt;filterCache&gt; filterCache 存储了无序的lucenedocumentid 集合。为 IndexSearcher 使用，当一个IndexSearcher 打开时，可以被重新赋于原来的值，或者使用旧的 IndexSearcher 的值，例如使用 LRUCache时，最近被访问的 Items将被赋予 IndexSearcher 。solr 默认是 FastLRUCache 。 &lt;queryResultCache&gt; 缓存查询的结果集的 docs的 id。 &lt;documentCache&gt; 缓存 document对象，因为 document中的内部 id是 transient, 所以autowarmed 为0 ，不能被 autowarmed。 &lt;enableLazyFieldLoading&gt; 保存的字段，如果不需要的话就懒加载，默认true。 &lt;queryResultWindowSize&gt;queryResultCache 的一个参数。 &lt;queryResultMaxDocsCached&gt; queryResultCache 的一个参数。 &lt;listener event\"newSearcher\"class=\"solr.QuerySenderListener\"&gt;query 的事件监听器。 &lt;useColdSearcher&gt;当一个检索请求到达时，如果现在没有注册的searcher，那么直接注册正在预热的 searcher并使用它。如果设为 false则所有请求都要 block，直到有 searcher完成预热。 &lt;maxWarmingSearchers&gt;后台同步预热的 searchers数量。&lt;requestDispatcherhandleSelect=\"false\"&gt; solr接受请求后如何处理，推荐新手使用false &lt;requestParsersenableRemoteStreaming=\"true\" multipartUploadLimitInKB=\"2048000\"formdataUploadLimitInKB=\"2048\" /&gt; 使系统能够接收远程流 &lt;httpCachingnever304=\"true\"&gt;http cache 参数，solr 不输出任何 HTTPCaching相关的头信息。&lt;requestHandler&gt; 接收请求，根据name值不同分发到不同的handler。 \"/select\" 检索 SearchHandler \"/query\" 检索 SearchHandler \"/get\" RealTimeGetHandler \"/browse\" SearcherHandler \"/update\" UpdateRequestHandler \"/update/json\" JsonUpdateRequestHandler \"/update/csv\" CSVRequestHandler \"/update/extract\"ExtractingRequestHandler \"/analysis/field\" FieldAnalysisRequestHandler \"/analysis/document\"DocumentAnalysisRequestHandler \"/admin/\" AdminHandlers \"/replication\" 复制，要有主，有从 &lt;searchComponent&gt; 注册searchComponent &lt;queryResponseWriter&gt; 返回数据 数据导入从数据库导入数据至solr。在wtt_core/conf/下新建hexo-data-config.xml(名字可自定义) 1234567891011121314&lt;dataConfig&gt; &lt;dataSource type=\"JdbcDataSource\" driver=\"com.mysql.jdbc.Driver\" url=\"jdbc:mysql://wentuotuo.com:3306/test?useUnicode=true&amp;amp;characterEncoding=UTF-8\" user=\"hexo\" password=\"iju_,sfe\"/&gt; &lt;document name=\"documents\"&gt; &lt;entity name=\"documents\" pk=\"id\" query=\"SELECT * FROM Hexo\" deltaQuery=\"select * from Hexo where date &gt; '$&#123;dataimporter.last_index_time&#125;'\"&gt; &lt;field column=\"ID\" name=\"id\" /&gt; &lt;field column=\"title\" name=\"title\" /&gt; &lt;field column=\"date\" name=\"date\" /&gt; &lt;field column=\"slug\" name=\"slug\" /&gt; &lt;field column=\"content\" name=\"content\" /&gt; &lt;/entity&gt; &lt;/document&gt;&lt;/dataConfig&gt; 在 solrconfig.xml 中，添加/修改 下面内容： 12345&lt;requestHandler name=\"/dataimport\" class=\"org.apache.solr.handler.dataimport.DataImportHandler\"&gt; &lt;lst name=\"defaults\"&gt; &lt;str name=\"config\"&gt;hexo-data-config.xml&lt;/str&gt; &lt;/lst&gt;&lt;/requestHandler&gt; 在界面上wtt_core核心中点击Dataimport，execute导入后： ErrorSolrCore Initialization Failures org.apache.solr.common.SolrException:org.apache.solr.common.SolrException: Error loading class ‘org.apache.solr.handler.dataimport.DataImportHandler’ 原因: 缺少包solr-dataimporthandler-X.X.X.jar这个jar包，默认在下载包的dist目录下 解决方法：在solrconfig.xml中增加下面一行1&lt;lib dir=\"/home/ymhe/software/solr-6.4.1/dist\" regex=\"solr-dataimporthandler-\\d.*\\.jar\" /&gt; 参考资料 Solr Data Import 快速入门","tags":[{"name":"大数据","slug":"大数据","permalink":"https://wentuotuo.com/tags/大数据/"},{"name":"Solr","slug":"Solr","permalink":"https://wentuotuo.com/tags/Solr/"}]},{"title":"Hbase 工具类","date":"2016-07-29T09:27:45.000Z","path":"2016/07/29/大数据/tool-unit-of-hbase/","text":"Hbase工具类，包含若干常用方法。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327package com.wentuotuo.utils;import java.io.IOException;import java.util.ArrayList;import java.util.List;import org.apache.hadoop.conf.Configuration;import org.apache.hadoop.hbase.Cell;import org.apache.hadoop.hbase.CellUtil;import org.apache.hadoop.hbase.ClusterStatus;import org.apache.hadoop.hbase.HBaseConfiguration;import org.apache.hadoop.hbase.HColumnDescriptor;import org.apache.hadoop.hbase.HTableDescriptor;import org.apache.hadoop.hbase.MasterNotRunningException;import org.apache.hadoop.hbase.ServerName;import org.apache.hadoop.hbase.TableName;import org.apache.hadoop.hbase.ZooKeeperConnectionException;import org.apache.hadoop.hbase.client.Delete;import org.apache.hadoop.hbase.client.Get;import org.apache.hadoop.hbase.client.HBaseAdmin;import org.apache.hadoop.hbase.client.HTable;import org.apache.hadoop.hbase.client.Put;import org.apache.hadoop.hbase.client.Result;import org.apache.hadoop.hbase.client.ResultScanner;import org.apache.hadoop.hbase.client.Scan;import org.apache.hadoop.hbase.filter.CompareFilter;import org.apache.hadoop.hbase.filter.Filter;import org.apache.hadoop.hbase.filter.FilterList;import org.apache.hadoop.hbase.filter.PageFilter;import org.apache.hadoop.hbase.filter.RowFilter;import org.apache.hadoop.hbase.filter.SubstringComparator;import org.apache.hadoop.hbase.util.Bytes;/** * Hbase工具类 * **/public class HbaseCommons &#123; // 设置hbase的配置文件，hbase会自动从xml中读取信息 static Configuration conf = HBaseConfiguration.create(); /** * 创建一个表 * * @param tableName * 表名字 * @param columnFamilys * 列簇 * **/ public static void createTable(String tableName, String[] columnFamilys) throws Exception &#123; // 创建表（创建表、删除表使用HBaseAdmin） HBaseAdmin admin = new HBaseAdmin(conf); if (admin.tableExists(tableName)) &#123; System.out.println(\"此表，已存在！\"); &#125; else &#123; // 旧的写法 // HTableDescriptor tableDesc=new HTableDescriptor(tableName); // 新的api HTableDescriptor tableDesc = new HTableDescriptor(TableName.valueOf(tableName)); for (String columnFamily : columnFamilys) &#123; tableDesc.addFamily(new HColumnDescriptor(columnFamily)); &#125; admin.createTable(tableDesc); System.out.println(\"建表成功!\"); &#125; admin.close();// 关闭释放资源 &#125; /** * 删除一个表 * * @param tableName * 删除的表名 */ public static void deleteTable(String tableName) throws Exception &#123; HBaseAdmin admin = new HBaseAdmin(conf); if (admin.tableExists(tableName)) &#123; admin.disableTable(tableName);// 禁用表 admin.deleteTable(tableName);// 删除表 System.out.println(\"删除表成功!\"); &#125; else &#123; System.out.println(\"删除的表不存在！\"); &#125; admin.close(); &#125; /** * 插入一条数据 * * @param tableName * 表名 * @param columnFamily * 列簇 * @param column * 列 * @param value * 值 ***/ public static void insertOneRow(String tableName, String rowkey, String columnFamily, String column, String value) throws Exception &#123; HTable table = new HTable(conf, tableName); Put put = new Put(Bytes.toBytes(rowkey)); put.add(Bytes.toBytes(columnFamily), Bytes.toBytes(column), Bytes.toBytes(value)); table.put(put);// 放入表 table.close();// 释放资源 &#125; /** * 批量添加数据 * * @param tableName * 表名字 * @param rows * rows的数据格式：\"rowskey,columnFamily,column,value\" * **/ public static void insertList(String tableName, List&lt;String&gt; rows) throws Exception &#123; HTable table = new HTable(conf, tableName); List&lt;Put&gt; list = new ArrayList&lt;Put&gt;(); for (String r : rows) &#123; String[] splited = r.split(\",\"); // 添加rowkey Put p = new Put(Bytes.toBytes(splited[0])); // 添加其他信息 p.add(Bytes.toBytes(splited[1]), Bytes.toBytes(splited[2]), Bytes.toBytes(splited[3])); list.add(p); &#125; table.put(list);// 批量添加 table.close();// 释放资源 &#125; /** * 删除一条数据 * * @param tableName * 表名 * @param row * rowkey行键 * */ public static void deleteOneRow(String tableName, String row) throws Exception &#123; HTable table = new HTable(conf, tableName); Delete delete = new Delete(Bytes.toBytes(row)); table.delete(delete); table.close(); &#125; /** * 删除多条数据 * * @param tableName * 表名 * @param rows * 行健集合 * **/ public static void deleteList(String tableName, String rows[]) throws Exception &#123; HTable table = new HTable(conf, tableName); List&lt;Delete&gt; list = new ArrayList&lt;Delete&gt;(); for (String row : rows) &#123; Delete del = new Delete(Bytes.toBytes(row)); list.add(del); &#125; table.delete(list); table.close();// 释放资源 &#125; /** * rowkey模糊条件查询 * * @param key * 模糊rowkey内容 * @throws Exception */ public static ResultScanner fuzzyScan(String tableName, String startKey, String endKey) throws Exception &#123; HTable table = new HTable(conf, tableName); Scan s = new Scan(); // 可以通过时间限定查询范围 // s.setStartRow(startKey.getBytes()); // s.setStopRow(endKey.getBytes()); return table.getScanner(s); &#125; /** * rowkey模糊条件查询 * * @param key * 模糊rowkey内容 * @param columnFalimy * 指定列簇 * @throws Exception */ public static void fuzzySearchFamily(String tableName, String key, String columnFalimy) throws Exception &#123; HTable table = new HTable(conf, tableName); Scan s = new Scan(); RowFilter filter = new RowFilter(CompareFilter.CompareOp.EQUAL, new SubstringComparator(key)); s.setFilter(filter); s.addFamily(columnFalimy.getBytes()); ResultScanner rs = table.getScanner(s); for (Result r : rs) &#123; printRecoder(r);// 打印记录 &#125; table.close();// 释放资源 &#125; /** * 获取一条数据，根据rowkey * * @param tableName * 表名 * @param row * 行健 * **/ public static Result getOneRow(String tableName, String row) throws Exception &#123; HTable table = new HTable(conf, tableName); Get get = new Get(Bytes.toBytes(row)); Result result = table.get(get); printRecoder(result);// 打印记录 table.close();// 释放资源 return result; &#125; /** * 查看某个表下的所有数据 * * @param tableName * 表名 */ public static void showAll(String tableName) throws Exception &#123; HTable table = new HTable(conf, tableName); Scan scan = new Scan(); scan.setStartRow(Bytes.toBytes(\"\")); scan.setStopRow(Bytes.toBytes(\"\")); ResultScanner rs = table.getScanner(scan); for (Result r : rs) &#123; printRecoder(r);// 打印记录 &#125; table.close();// 释放资源 &#125; /** * 具体查询row中的列簇的数据 * * @param tableName * 表名 * @param rowKey * 行健 * @param columnFalimy * 列簇 */ public static void getFamily(String tableName, String rowKey, String columnFalimy) throws Exception &#123; HTable table = new HTable(conf, tableName); Get get = new Get(Bytes.toBytes(rowKey)); get.addFamily(Bytes.toBytes(columnFalimy)); Result r = table.get(get); printRecoder(r); table.close();// 释放资源 &#125; /** * 具体查询row中的一条数据 * * @param tableName * 表名 * @param rowKey * 行健 * @param columnFalimy * 列簇 * @param column * 值 */ public static void getColumn(String tableName, String rowKey, String columnFalimy, String column) throws Exception &#123; HTable table = new HTable(conf, tableName); Get get = new Get(Bytes.toBytes(rowKey)); get.addColumn(Bytes.toBytes(columnFalimy), Bytes.toBytes(column)); Result r = table.get(get); printRecoder(r); table.close();// 释放资源 &#125; /** * 打印一条记录的详情 * */ public static void printRecoder(Result result) throws Exception &#123; for (Cell cell : result.rawCells()) &#123; System.out.print(\"行健: \" + new String(CellUtil.cloneRow(cell))); System.out.print(\" 列簇: \" + new String(CellUtil.cloneFamily(cell))); System.out.print(\" 列: \" + new String(CellUtil.cloneQualifier(cell))); System.out.print(\" 值: \" + new String(CellUtil.cloneValue(cell))); System.out.println(\" 时间戳: \" + cell.getTimestamp()); &#125; &#125; public static void getRecoder(Result result) &#123; for (Cell cell : result.rawCells()) &#123; System.out.print(\"行健: \" + new String(CellUtil.cloneRow(cell))); System.out.print(\" 列簇: \" + new String(CellUtil.cloneFamily(cell))); System.out.print(\" 列: \" + new String(CellUtil.cloneQualifier(cell))); System.out.print(\" 值: \" + new String(CellUtil.cloneValue(cell))); System.out.println(\" 时间戳: \" + cell.getTimestamp()); &#125; &#125; public static void main(String[] args) throws Exception &#123; List&lt;String&gt; list = new ArrayList&lt;String&gt;(); for (int i = 1; i &lt; 101; i++) &#123; String s = i+\",data,info,\"+System.currentTimeMillis()+\"#info#\"+i; String ss = i+\",data,other,\"+System.currentTimeMillis()+\"#other#\"+i; list.add(s); list.add(ss); &#125; HbaseCommons.insertList(\"record\", list); &#125;&#125;","tags":[{"name":"大数据","slug":"大数据","permalink":"https://wentuotuo.com/tags/大数据/"},{"name":"Hbase","slug":"Hbase","permalink":"https://wentuotuo.com/tags/Hbase/"}]},{"title":"Sqoop抽数","date":"2016-07-06T08:45:22.000Z","path":"2016/07/06/大数据/manual-of-sqoop/","text":"从Oracle抽数到Hbase1sudo -u hdfs sqoop import -connect jdbc:oracle:thin:@192.168.61.27:1521:orcl -username pira -password pira -table DT_CLEAR_DATA --hbase-table dt_clear_data --column-family info --hbase-row-key ID --hbase-create-table -columns ID,TEXT 从Oracle抽数到Hive1sudo -u hdfs sqoop import --driver oracle.jdbc.driver.OracleDriver --connect jdbc:oracle:thin:@192.168.1.104:1521:ora11g --username crpiradev --password crpiradev --append --query &quot;SELECT * FROM DT_CLEAR_DATA WHERE 1=1 AND \\$CONDITIONS&quot; --target-dir /usr/local/tmp/hivebackup --split-by DT_CLEAR_DATA.ID 从Oracle抽数到Hive 根据Oracle中某表，在HIVE中建立相同的表 1sqoop create-hive-table -connect jdbc:oracle:thin:@192.168.1.51:1521:orcl -username pira -password &apos;pira!51&apos; -table DT_MANAGE --hive-table fall_in_db.DT_MANAGE 抽数 1LOAD DATA INPATH &apos;/amarsoft/test/hivebackup/dt_clear_data/part-m-*&apos; OVERWRITE INTO TABLE dt_clear_data","tags":[{"name":"大数据","slug":"大数据","permalink":"https://wentuotuo.com/tags/大数据/"},{"name":"Sqoop","slug":"Sqoop","permalink":"https://wentuotuo.com/tags/Sqoop/"}]},{"title":"Java实现Jaccard算法去重","date":"2016-04-09T11:25:34.000Z","path":"2016/04/09/Java/jaccard-algorithm-in-java/","text":"最近项目需求，需要对大量大文本进行去重，研究了一下相关算法，最后确定在Jaccard算法上，这里记录下实现过程。 Jaccard 算法算法相关简介网上已经有很多介绍了，这里推荐一篇个人认为写得还不错的：传送门 分词关于分词也有很多选择，我这里选择的是HanLP的分词，因为对中文的支持做的比较好。 HanLP官网 倒排索引记得当时在研究生语义分析课的时候学习过倒排索引的概念，但是实际运用中才发现神奇，倒排过后查询效率提升一个台阶。 代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121package com.amarsoft.proj.jaccard;import java.io.IOException;import java.sql.Connection;import java.sql.PreparedStatement;import java.sql.ResultSet;import java.sql.SQLException;import java.sql.Statement;import java.util.HashMap;import java.util.LinkedList;import java.util.List;import java.util.Map;import org.apache.solr.client.solrj.SolrServer;import org.apache.solr.client.solrj.SolrServerException;import org.apache.solr.client.solrj.impl.HttpSolrServer;import org.apache.solr.common.SolrInputDocument;import com.amarsoft.are.ARE;import com.amarsoft.proj.struct.TextModel;public class ClearText &#123;/** * 去重 * * @param serialNoTextModelMap * 待去重Map */ public static Map&lt;String, TextModel&gt; clearNewText(Map&lt;String, TextModel&gt; serialNoTextModelMap) &#123; Map&lt;String, TextModel&gt; repTextModelMap = new HashMap&lt;String, TextModel&gt;(); // 对待去重文章Map进行排序 List&lt;Map.Entry&lt;String, TextModel&gt;&gt; sortedSerialNoTextMapEntry = new CommonMethod() .sortByWordsCount(serialNoTextModelMap, 2); Map&lt;String, List&lt;TextModel&gt;&gt; wordsTextListMap = new HashMap&lt;String, List&lt;TextModel&gt;&gt;();// 存储&lt;分词,有该分词的所有文章模型列表&gt;的Map(倒排列表) for (Map.Entry&lt;String, TextModel&gt; entry : sortedSerialNoTextMapEntry) &#123; // 遍历排序后的Map String serialNo = entry.getKey();// 文章序列号 String[] wordsSet = null; wordsSet = HanLPCutWords.getWords(entry.getValue().getText());// 从数据库获取分词 Map&lt;String, Integer&gt; currentWordCountMap = new HashMap&lt;String, Integer&gt;();// 当前文章每个分词出现的次数 Map&lt;String, Integer&gt; serialNoDupCountMap = new HashMap&lt;String, Integer&gt;();// 存储与该文章的分词重复的文章的serialno和分词重复次数的Map // 遍历分词数组 for (String word : wordsSet) &#123; // 该文章当前该分词数量+1 if (currentWordCountMap.containsKey(word)) &#123; int cCount = currentWordCountMap.get(word); cCount++; currentWordCountMap.put(word, cCount); &#125; else &#123; currentWordCountMap.put(word, 1); &#125; if (wordsTextListMap.containsKey(word)) &#123;// 分词已经存在于wordsTextListMap中了 // 根据重复的分词所属的文章，将重复分词数记录到serialNoDupCountMap List&lt;TextModel&gt; textModelList = wordsTextListMap.get(word);// 取得该分词对应的文章模型列表 for (TextModel textModel : textModelList) &#123; String dupSerialNo = textModel.getSerialNo();// 与该分词有重复的文章的serialno if (entry.getKey().equals(dupSerialNo)) &#123; continue;// 跳过自己 &#125; // 跳过word数量小于当前遍历文章word数的文章。// if (textModel.getCurrentWordCount() &lt; currentWordCountMap.get(word)) &#123;// continue;// &#125; // 将所有包含该分词的文章对应的重复次数+1 if (serialNoDupCountMap.containsKey(dupSerialNo)) &#123; int dupCount = serialNoDupCountMap.get(dupSerialNo); dupCount++; serialNoDupCountMap.put(dupSerialNo, dupCount); &#125; else &#123; serialNoDupCountMap.put(dupSerialNo, 1); &#125; &#125; // 将本次遍历的文章加入到wordsTextListMap List&lt;TextModel&gt; tModelList = wordsTextListMap.get(word); if (!tModelList.contains(entry.getValue())) &#123; TextModel tModel = entry.getValue(); tModel.setCurrentWordCount(tModel.getCurrentWordCount() + 1); tModelList.add(tModel); wordsTextListMap.put(word, tModelList); &#125; &#125; else &#123;// 分词不存在,新增 List&lt;TextModel&gt; tModelList = new LinkedList&lt;TextModel&gt;(); TextModel tModel = entry.getValue(); tModel.setCurrentWordCount(1); tModelList.add(tModel); wordsTextListMap.put(word, tModelList); &#125; &#125; // 遍历分词数组结束,此时已经处理完该文章对应的所有分词 // 去重，serialNoDupCountMap此时存放了之前遍历过的文章与本次遍历的文章分词重复的个数,遍历它，计算重复分词数占较少分词数文章的比例，标记超过阈值的任务文章 int currentWordsCount = entry.getValue().getWordCount();// 当前遍历的文章的分词数（因为已经倒序过了，所以是目前最少的） // 遍历 for (Map.Entry&lt;String, Integer&gt; dealRepEntry : serialNoDupCountMap.entrySet()) &#123; // 若比例超过阈值，判定为重复文章，此时将较短（即本次遍历的）文章标记为重复，并记录它与谁重复(RID) double rate = dealRepEntry.getValue() * 1.0 / currentWordsCount;// 重复比例 if (rate &gt; JaccardTextSimilarity.ACCURACY) &#123; String RID = dealRepEntry.getKey(); if (RID.equals(serialNo)) &#123; continue; &#125; TextModel repTextModel = serialNoTextModelMap.get(serialNo); String repStatus = \"-2\";// 算法重复标志 -2 repTextModel.setStatus(repStatus); repTextModel.setRID(RID); //debug: ARE.getLog().info(\"发现重复文章：\" + serialNo + \"和\" + RID); // 将重复的textModel存入repTextModelMap. repTextModelMap.put(serialNo, repTextModel); &#125; &#125; &#125; // 遍历排序后的Map结束 return repTextModelMap; &#125;&#125;","tags":[{"name":"Java","slug":"Java","permalink":"https://wentuotuo.com/tags/Java/"},{"name":"Jaccard","slug":"Jaccard","permalink":"https://wentuotuo.com/tags/Jaccard/"},{"name":"算法","slug":"算法","permalink":"https://wentuotuo.com/tags/算法/"}]},{"title":"使用UUID","date":"2016-02-21T08:46:20.000Z","path":"2016/02/21/Java/UUID-usage/","text":"什么是UUIDUUID含义是通用唯一识别码 (Universally Unique Identifier)，这是一个软件建构的标准，也是被开源软件基金会 (Open Software Foundation, OSF) 的组织在分布式计算环境 (Distributed Computing Environment, DCE) 领域的一部份。UUID 的目的，是让分布式系统中的所有元素，都能有唯一的辨识资讯，而不需要透过中央控制端来做辨识资讯的指定。如此一来，每个人都可以建立不与其它人冲突的 UUID。在这样的情况下，就不需考虑数据库建立时的名称重复问题。目前最广泛应用的 UUID，即是微软的 Microsoft’s Globally Unique Identifiers (GUIDs)，而其他重要的应用，则有 Linux ext2/ext3 档案系统、LUKS 加密分割区、GNOME、KDE、Mac OS X 等等。UUID由以下几部分的组成：当前日期和时间(UUID的第一个部分与时间有关，如果你在生成一个UUID之后，过几秒又生成一个UUID，则第一个部分不同，其余相同)，时钟序列，全局唯一的IEEE机器识别号（如果有网卡，从网卡获得，没有网卡以其他方式获得），UUID的唯一缺陷在于生成的结果串会比较长。 生成UUID生成UUID的java实现非常简单：123456789import java.util.UUID;public class UUIDTest &#123; public static void main(String[] args)&#123; UUID uuid = UUID.randomUUID(); String result = uuid.toString(); System.out.println(result); &#125;&#125; 上面程序生成的UUID: 1d421c2c-b6d7-4f9b-8456-99b6b36199ec 实际情况下，我们通常不需要中间的横杠 以下是完整的实现和测试 123456789101112131415161718192021222324252627public class UUIDTest &#123; public static String getUUID() &#123; UUID uuid = UUID.randomUUID(); String str = uuid.toString(); // 去掉\"-\"符号 String temp = str.substring(0, 8) + str.substring(9, 13) + str.substring(14, 18) + str.substring(19, 23) + str.substring(24); return str+\",\"+temp; &#125; //获得指定数量的UUID public static String[] getUUID(int num) &#123; if (num &lt; 1) &#123; return null; &#125; String[] strings = new String[num]; for (int i = 0; i &lt; num; i++) &#123; strings[i] = getUUID(); &#125; return strings; &#125; public static void main(String[] args) &#123; String[] strings = getUUID(10); for (int i = 0; i &lt; strings.length; i++) &#123; System.out.println(\"UUID[\"+i+\"]=====&gt;\"+strings[i]); &#125; &#125;&#125; 测试结果 12345678910UUID[0]=====&gt;09a1512e-dc98-49fd-bc0d-ee65f42a59fa,09a1512edc9849fdbc0dee65f42a59faUUID[1]=====&gt;545886f2-4de0-4297-8005-4c25de5923ff,545886f24de0429780054c25de5923ffUUID[2]=====&gt;36cb776c-8349-4106-9a11-26e3b3ad3a64,36cb776c834941069a1126e3b3ad3a64UUID[3]=====&gt;9096e155-0a28-4e43-b556-676a2b196f07,9096e1550a284e43b556676a2b196f07UUID[4]=====&gt;0b70094c-5502-490b-aa86-a73955b9389b,0b70094c5502490baa86a73955b9389bUUID[5]=====&gt;5b0483a1-7e7b-4f29-a0a9-fcf55136a31c,5b0483a17e7b4f29a0a9fcf55136a31cUUID[6]=====&gt;bbd13a23-b2c7-4074-9be3-1c15e9950f98,bbd13a23b2c740749be31c15e9950f98UUID[7]=====&gt;c2f170f1-3c15-4efb-99f5-710848d446f4,c2f170f13c154efb99f5710848d446f4UUID[8]=====&gt;a69c0a50-294c-45bb-ab31-5a70989c94b8,a69c0a50294c45bbab315a70989c94b8UUID[9]=====&gt;865a18ed-ac81-41ef-a79f-95d0ed3c829e,865a18edac8141efa79f95d0ed3c829e","tags":[{"name":"Java","slug":"Java","permalink":"https://wentuotuo.com/tags/Java/"},{"name":"UUID","slug":"UUID","permalink":"https://wentuotuo.com/tags/UUID/"}]},{"title":"JDK安装","date":"2016-01-13T19:06:35.000Z","path":"2016/01/14/Java/JDK-install/","text":"环境Linux版本：CentOS 6.5、Ubuntu 12.04.5JDK版本：JDK 1.7 首先卸载自带openjdk，Ubuntu： 1apt-get remove openjdk* 如果是centos 12345678910111213先查看 rpm -qa | grep java显示如下信息：java-1.4.2-gcj-compat-1.4.2.0-40jpp.115java-1.6.0-openjdk-1.6.0.0-1.7.b09.el5卸载：rpm -e --nodeps java-1.4.2-gcj-compat-1.4.2.0-40jpp.115rpm -e --nodeps java-1.6.0-openjdk-1.6.0.0-1.7.b09.el5还有一些其他的命令rpm -qa | grep gcjrpm -qa | grep jdk如果出现找不到openjdk source的话，那么还可以这样卸载yum -y remove java java-1.4.2-gcj-compat-1.4.2.0-40jpp.115yum -y remove java java-1.6.0-openjdk-1.6.0.0-1.7.b09.el5 方法一：手动解压JDK的压缩包，然后设置环境变量1.在/usr/目录下创建java目录12[root@localhost ~]# mkdir/usr/java[root@localhost ~]# cd /usr/java 2.下载，然后解压12[root@localhost java]# curl -O http://download.oracle.com/otn-pub/java/jdk/7u79-b15/jdk-7u79-linux-x64.tar.gz [root@localhost java]# tar -zxvf jdk-7u79-linux-x64.tar.gz 3.设置环境变量1[root@localhost java]# vi /etc/profile 添加如下内容到文件末尾：123456#set java environmentJAVA_HOME=/usr/java/jdk1.7.0_79JRE_HOME=/usr/java/jdk1.7.0_79/jreCLASS_PATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/libPATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/binexport JAVA_HOME JRE_HOME CLASS_PATH PATH 让修改生效：1[root@localhost java]# source /etc/profile 4.验证1234[root@localhost java]# java -versionjava version &quot;1.7.0_79&quot;Java(TM) SE Runtime Environment (build 1.7.0_79-b15)Java HotSpot(TM) 64-Bit Server VM (build 24.79-b02, mixed mode) 方法二：用yum安装JDK(CentOS)1.查看yum库中都有哪些jdk版本12345678910111213141516171819[root@localhost ~]# yum search java|grep jdkldapjdk-javadoc.x86_64 : Javadoc for ldapjdkjava-1.6.0-openjdk.x86_64 : OpenJDK Runtime Environmentjava-1.6.0-openjdk-demo.x86_64 : OpenJDK Demosjava-1.6.0-openjdk-devel.x86_64 : OpenJDK Development Environmentjava-1.6.0-openjdk-javadoc.x86_64 : OpenJDK API Documentationjava-1.6.0-openjdk-src.x86_64 : OpenJDK Source Bundlejava-1.7.0-openjdk.x86_64 : OpenJDK Runtime Environmentjava-1.7.0-openjdk-demo.x86_64 : OpenJDK Demosjava-1.7.0-openjdk-devel.x86_64 : OpenJDK Development Environmentjava-1.7.0-openjdk-javadoc.noarch : OpenJDK API Documentationjava-1.7.0-openjdk-src.x86_64 : OpenJDK Source Bundlejava-1.8.0-openjdk.x86_64 : OpenJDK Runtime Environmentjava-1.8.0-openjdk-demo.x86_64 : OpenJDK Demosjava-1.8.0-openjdk-devel.x86_64 : OpenJDK Development Environmentjava-1.8.0-openjdk-headless.x86_64 : OpenJDK Runtime Environmentjava-1.8.0-openjdk-javadoc.noarch : OpenJDK API Documentationjava-1.8.0-openjdk-src.x86_64 : OpenJDK Source Bundleldapjdk.x86_64 : The Mozilla LDAP Java SDK 2.选择版本，进行安装 我们这里安装1.7版本1[root@localhost ~]# yum install java-1.7.0-openjdk 安装完之后，默认的安装目录是在:1/usr/lib/jvm/java-1.7.0-openjdk-1.7.0.75.x86_64 3.设置环境变量1[root@localhost ~]# vi /etc/profile 添加如下内容：123456#set java environmentJAVA_HOME=/usr/lib/jvm/java-1.7.0-openjdk-1.7.0.75.x86_64JRE_HOME=$JAVA_HOME/jreCLASS_PATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/libPATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/binexport JAVA_HOME JRE_HOME CLASS_PATH PATH 让修改生效：1[root@localhost java]# source /etc/profile 3.验证 同上。 注：因为采用yum安装jdk，系统考虑到多版本的问题，会用alternatives进行版本控制。开始，相应版本的jdk安装在/usr/lib/jvm/之后，会在alternatives中注册，在/etc/alternatives目录下会产生一些链接到/usr/lib/jvm/中刚安装好的jdk版本。 在/usr/bin下面会有链接到/etc/alternatives的相应的文件。比如，/usr/bin下面会有一个链接文件java的映射关系如下： /usr/bin/java-&gt;/etc/alternatives/java/etc/alternatives/java-&gt; /usr/lib/jvm/jre-1.7.0-openjdk.x86_64/bin/java这样，java命令不用设置环境变量，就可以正常运行了。但如果对于tomcat或其他软件来说还是要设置环境变量。 同样，如果安装新的版本jdk，就会重新链接到最新安装的jdk版本。当然，也可以使用alternatives修改所要使用的版本。 方法三：用rpm安装JDK1.下载1[hadoop@localhost ~]$ curl -O http://download.oracle.com/otn-pub/java/jdk/7u79-b15/jdk-7u79-linux-x64.rpm 2.使用rpm命令安装12345678910[root@localhost ~]# rpm -ivh jdk-7u79-linux-x64.rpmPreparing... ########################################### [100%] 1:jdk ###########################################[100%]Unpacking JAR files... rt.jar... jsse.jar... charsets.jar... tools.jar... localedata.jar... jfxrt.jar... 3.设置环境变量[root@localhost java]# vi /etc/profile添加如下内容：123456#set java environmentJAVA_HOME=/usr/java/jdk1.7.0_79JRE_HOME=/usr/java/jdk1.7.0_79/jreCLASS_PATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/libPATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/binexport JAVA_HOME JRE_HOME CLASS_PATH PATH 让修改生效：1[root@localhost java]# source /etc/profile 4.验证1234[root@localhost java]# java -versionjava version &quot;1.7.0_79&quot;Java(TM) SE Runtime Environment (build 1.7.0_79-b15)Java HotSpot(TM) 64-Bit Server VM (build 24.79-b02, mixed mode) 和yum安装类似，不用设置环境变量就可以，运行java命令。rpm安装方式默认会把jdk安装到/usr/java/jdk1.7.0_79，然后通过三层链接，链接到/usr/bin,具体链接如下：1234567891011121314[root@localhost ~]# cd /bin[root@localhost bin]# ll|grep javalrwxrwxrwx. 1 root root 25 Mar 28 11:24 jar -&gt;/usr/java/default/bin/jarlrwxrwxrwx. 1 root root 26 Mar 28 11:24 java -&gt; /usr/java/default/bin/javalrwxrwxrwx. 1 root root 27 Mar 28 11:24 javac -&gt;/usr/java/default/bin/javaclrwxrwxrwx. 1 root root 29 Mar 28 11:24 javadoc -&gt;/usr/java/default/bin/javadoclrwxrwxrwx. 1 root root 28 Mar 28 11:24 javaws -&gt;/usr/java/default/bin/javawslrwxrwxrwx. 1 root root 30 Mar 28 11:24 jcontrol -&gt;/usr/java/default/bin/jcontrol[root@localhost bin]# cd /usr/java/[root@localhost java]# lltotal 4lrwxrwxrwx. 1 root root 16 Mar 28 11:24 default-&gt; /usr/java/latestdrwxr-xr-x. 8 root root 4096 Mar 28 11:24 jdk1.7.0_79lrwxrwxrwx. 1 root root 21 Mar 28 11:24 latest -&gt; /usr/java/jdk1.7.0_79 方法四：Ubuntu 上使用apt-get安装JDK1.查看apt库都有哪些jdk版本1234567891011121314151617181920212223root@Itble:~# apt-cache search java|grep jdkdefault-jdk - Standard Java or Java compatible Development Kitdefault-jdk-doc - Standard Java or Java compatible Development Kit (documentation)gcj-4.6-jdk - gcj and classpath development tools for Java(TM)gcj-jdk - gcj and classpath development tools for Java(TM)openjdk-6-dbg - Java runtime based on OpenJDK (debugging symbols)openjdk-6-demo - Java runtime based on OpenJDK (demos and examples)openjdk-6-doc - OpenJDK Development Kit (JDK) documentationopenjdk-6-jdk - OpenJDK Development Kit (JDK)openjdk-6-jre-lib - OpenJDK Java runtime (architecture independent libraries)openjdk-6-source - OpenJDK Development Kit (JDK) source filesopenjdk-7-dbg - Java runtime based on OpenJDK (debugging symbols)openjdk-7-demo - Java runtime based on OpenJDK (demos and examples)openjdk-7-doc - OpenJDK Development Kit (JDK) documentationopenjdk-7-jdk - OpenJDK Development Kit (JDK)openjdk-7-source - OpenJDK Development Kit (JDK) source filesuwsgi-plugin-jvm-openjdk-6 - Java plugin for uWSGI (OpenJDK 6)uwsgi-plugin-jwsgi-openjdk-6 - JWSGI plugin for uWSGI (OpenJDK 6)openjdk-6-jre - OpenJDK Java runtime, using Hotspot JITopenjdk-6-jre-headless - OpenJDK Java runtime, using Hotspot JIT (headless)openjdk-7-jre - OpenJDK Java runtime, using Hotspot JITopenjdk-7-jre-headless - OpenJDK Java runtime, using Hotspot JIT (headless)openjdk-7-jre-lib - OpenJDK Java runtime (architecture independent libraries) 2.选择版本进行安装1root@Itble:~# apt-get install openjdk-7-jdk 3.设置环境变量1root@Itble:~# vi /etc/profile 添加如下内容：123456#set java environmentJAVA_HOME=/usr/lib/jvm/java-1.7.0-openjdk-amd64JRE_HOME=$JAVA_HOME/jreCLASS_PATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/libPATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/binexport JAVA_HOME JRE_HOME CLASS_PATH PATH 让修改生效：1root@Itble:~# source /etc/profile 4.验证1234root@Itble:~# java -versionjava version &quot;1.7.0_79&quot;OpenJDK Runtime Environment (IcedTea 2.5.5) (7u79-2.5.5-0ubuntu0.12.04.1)OpenJDK 64-Bit Server VM (build 24.79-b02, mixed mode) Ubuntu的apt-get安装方式和CentOS的yum安装方式很类似，这里就不再啰嗦。","tags":[{"name":"Java","slug":"Java","permalink":"https://wentuotuo.com/tags/Java/"},{"name":"Jdk","slug":"Jdk","permalink":"https://wentuotuo.com/tags/Jdk/"}]},{"title":"JDBC使用游标分页读取大量数据","date":"2015-12-24T16:00:00.000Z","path":"2015/12/25/Java/use-cursor-read-bigdata/","text":"今天同步mysql中一张很大的表到另外一个数据库，折腾了半天写的程序报OOM。后来使用了limit限制每次读取量，新的问题又来了：程序跑到后面莫名卡死，而且效率低下。各种搜索，发现原来jdbc有游标分页读取的功能。 MySQL JDBC默认客户端数据接收方式为从服务器一次取出所有数据放在客户端内存中，fetch size参数不起作用，当一条SQL返回数据量较大时可能会出现JVM OOM。 解决方法： 设置游标读取 123ps = conn.prepareStatement(sql, ResultSet.TYPE_FORWARD_ONLY, ResultSet.CONCUR_READ_ONLY);ps.setFetchSize(Integer.MIN_VALUE);setFetchDirection(ResultSet.FETCH_REVERSE); 完整代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667import java.sql.*;public class TestCursor &#123; public static long importData(String sql) &#123; String url = \"jdbc:mysql://192.168.61.78:3306/bdsyn?user=pira&amp;password=pira&amp;amp;useUnicode=true&amp;amp;characterEncoding=UTF-8&amp;amp;autoReconnect=true&amp;amp;failOverReadOnly=false&amp;amp;maxReconnects=10&amp;amp;rewriteBatchedStatements=true&amp;amp;useCursorFetch=true&amp;amp;defaultFetchSize=1000\"; try &#123; Class.forName(\"com.mysql.jdbc.Driver\"); &#125; catch (ClassNotFoundException e1) &#123; e1.printStackTrace(); &#125; long count = 0; Connection con = null; PreparedStatement ps = null; Statement st = null; ResultSet rs = null; try &#123; con = DriverManager.getConnection(url); ps = con.prepareStatement(sql, ResultSet.TYPE_FORWARD_ONLY, ResultSet.CONCUR_READ_ONLY); ps.setFetchSize(Integer.MIN_VALUE); ps.setFetchDirection(ResultSet.FETCH_REVERSE); rs = ps.executeQuery(); while (rs.next()) &#123; count++; if (count % 10000 == 0) &#123; System.out.println(\" 第 \" + count + \" 条数据！\"); &#125; &#125; System.out.println(\"取回数据量为 \" + count + \" 行！\"); &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125; finally &#123; try &#123; if (rs != null) &#123; rs.close(); &#125; if (ps != null) &#123; ps.close(); &#125; if (st != null) &#123; st.close(); &#125; if (ps != null) &#123; ps.close(); &#125; &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125; &#125; return count; &#125; public static void main(String[] args)&#123; String sql= \"select * from dt_clear_data\"; importData(sql); &#125;&#125;","tags":[{"name":"Java","slug":"Java","permalink":"https://wentuotuo.com/tags/Java/"},{"name":"数据库","slug":"数据库","permalink":"https://wentuotuo.com/tags/数据库/"}]}]